{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train-location {local,cloud}]\n",
      "                             [--model-name MODEL_NAME] --job-dir JOB_DIR\n",
      "                             [--distribution-strategy {tf.distribute.MirroredStrategy,tf.distribute.experimental.ParameterServerStrategy,tf.distribute.experimental.MultiWorkerMirroredStrategy,tf.distribute.experimental.CentralStorageStrategy,tf.distribute.experimental.TPUStrategy,tf.distribute.OneDeviceStrategy}]\n",
      "                             [--training-function {train_keras_sequential,train_keras_functional,train_keras_functional_wide_and_deep,train_keras_to_estimator_functional,train_keras_to_estimator_sequential,train_estimator,train_estimator_wide_and_deep,train_keras_functional_no_feature_layer,train_custom_loop_keras_sequential,train_custom_loop_keras_model_functional_no_feature_layer,train_keras_sequential_wide_and_deep}]\n",
      "                             [--batch-size BATCH_SIZE]\n",
      "                             [--dataset-size {full,small}]\n",
      "                             [--dataset-source {bq,gcs}]\n",
      "                             [--num-epochs NUM_EPOCHS]\n",
      "                             [--embeddings-mode {n,o,n,e, ,m,a,n,u,a,l, ,h,a,s,h,b,u,c,k,e,t, ,v,o,c,a,b,u,l,a,r}]\n",
      "                             [--tensorboard]\n",
      "                             [--ai-platform-mode AI_PLATFORM_MODE]\n",
      "                             [--image-name IMAGE_NAME] [--no-gpu]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --job-dir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import GoogleAPIError\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import tensorflow_io as tf_io\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from tensorflow.python.data.experimental.ops import interleave_ops\n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "import google.cloud.logging\n",
    "\n",
    "import argparse\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "class BatchAccuracyAndLossSummaryCallback(tf.keras.callbacks.Callback):\n",
    "  # TODO: make it dist. strat. compartible\n",
    "  def __init__(self, log_dir, dataset_size):\n",
    "    # Callback should only write summaries on the chief when in a Multi-Worker setting.\n",
    "    self._chief_worker_only = True\n",
    "    self.update_freq = 10 if dataset_size == DATASET_SIZE_TYPE.small else 500\n",
    "    #file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "    #file_writer.set_as_default()\n",
    "    self.writer = SummaryWriter(log_dir +'/scalar_metrics')\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.epoch = epoch\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    if batch % self.update_freq == 0:\n",
    "      if 'accuracy' in logs:\n",
    "        self.writer.add_scalar('accuracy/train_epoch_{}'.format(self.epoch), logs['accuracy'], batch)\n",
    "        self.writer.add_scalars('accuracy/combined', {'train_epoch_{}'.format(self.epoch):logs['accuracy']}, batch)\n",
    "      if 'loss' in logs:\n",
    "        self.writer.add_scalar('loss/train_epoch_{}'.format(self.epoch), logs['loss'], batch)\n",
    "        self.writer.add_scalars('loss/combined', {'train_epoch_{}'.format(self.epoch):logs['loss']}, batch)\n",
    "  def on_test_batch_end(self, batch, logs=None):\n",
    "    if batch % self.update_freq // 10 == 0:\n",
    "      if 'accuracy' in logs:\n",
    "        self.writer.add_scalar('accuracy/test_epoch_{}'.format(self.epoch), logs['accuracy'], batch)\n",
    "        self.writer.add_scalars('accuracy/combined', {'test_epoch_{}'.format(self.epoch):logs['accuracy']}, batch)\n",
    "      if 'loss' in logs:\n",
    "        self.writer.add_scalar('loss/test_epoch_{}'.format(self.epoch), logs['loss'], batch)\n",
    "        self.writer.add_scalars('loss/combined', {'test_epoch_{}'.format(self.epoch):logs['loss']}, batch)\n",
    "  def on_train_end(self, logs=None):\n",
    "    self.writer.close()\n",
    "\n",
    "\n",
    "class TrainTimeCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.epoch_start_time = datetime.datetime.now()\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    logging.info('\\nepoch train time: (hh:mm:ss.ms) {}'.format(datetime.datetime.now() - self.epoch_start_time))\n",
    "    if not self.params is None:\n",
    "      if 'steps' in self.params:\n",
    "        epoch_milliseconds = (datetime.datetime.now() - self.epoch_start_time).total_seconds() * 1000\n",
    "        logging.info('{} ms/step'.format(epoch_milliseconds / self.params['steps']))\n",
    "      if BATCH_SIZE is not None:\n",
    "        logging.info('{} microseconds/example'.format(1000 * epoch_milliseconds  / self.params['steps'] / BATCH_SIZE))\n",
    "\n",
    "  def on_train_begin(self, logs=None):\n",
    "    self.start_training_time = datetime.datetime.now()\n",
    "\n",
    "  def on_train_end(self, logs=None):\n",
    "    logging.info('total train time: (hh:mm:ss.ms) {}'.format(datetime.datetime.now() - self.start_training_time))\n",
    "\n",
    "LOCATION = 'us'\n",
    "PROJECT_ID = \"alekseyv-scalableai-dev\" # TODO: replace with your project name\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"alekseyv-scalableai-dev-077efe757ef6.json\" # TODO: replace with your key name\n",
    "GOOGLE_APPLICATION_CREDENTIALS_GCS_BUCKET = 'gs://alekseyv-scalableai-dev-private-bucket/criteo' # TODO: replace with the path to the GCS bucket your project has access to\n",
    "\n",
    "DATASET_ID = 'criteo_kaggle'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "EMBEDDINGS_MODE_TYPE_VALUES = 'none manual hashbucket vocabular'\n",
    "EMBEDDINGS_MODE_TYPE = Enum('EMBEDDINGS_MODE_TYPE', 'none manual hashbucket vocabular')\n",
    "EMBEDDINGS_MODE = EMBEDDINGS_MODE_TYPE.hashbucket\n",
    "\n",
    "FULL_TRAIN_DATASET_SIZE = 36670642 # select count(1) from `alekseyv-scalableai-dev.criteo_kaggle.train`\n",
    "SMALL_TRAIN_DATASET_SIZE = 366715  # select count(1) from `alekseyv-scalableai-dev.criteo_kaggle.train_small`\n",
    "\n",
    "TRAIN_LOCATION_TYPE_VALUES = 'local cloud'\n",
    "TRAIN_LOCATION_TYPE = Enum('TRAIN_LOCATION_TYPE', TRAIN_LOCATION_TYPE_VALUES)\n",
    "TRAIN_LOCATION = TRAIN_LOCATION_TYPE.local\n",
    "\n",
    "# https://www.tensorflow.org/guide/distributed_training\n",
    "DISTRIBUTION_STRATEGY_TYPE = None\n",
    "DISTRIBUTION_STRATEGY_TYPE_VALUES = 'tf.distribute.MirroredStrategy tf.distribute.experimental.ParameterServerStrategy ' \\\n",
    "  'tf.distribute.experimental.MultiWorkerMirroredStrategy tf.distribute.experimental.CentralStorageStrategy ' \\\n",
    "  'tf.distribute.experimental.TPUStrategy tf.distribute.OneDeviceStrategy'\n",
    "TRAINING_FUNCTION_VALUES = 'train_keras_sequential train_keras_functional train_keras_functional_wide_and_deep ' \\\n",
    "  'train_keras_to_estimator_functional train_keras_to_estimator_sequential train_estimator train_estimator_wide_and_deep ' \\\n",
    "  'train_keras_functional_no_feature_layer train_custom_loop_keras_sequential train_custom_loop_keras_model_functional_no_feature_layer ' \\\n",
    "  'train_keras_sequential_wide_and_deep'\n",
    "\n",
    "DATASET_SIZE_TYPE = Enum('DATASET_SIZE_TYPE', 'full small')\n",
    "DATASET_SIZE = DATASET_SIZE_TYPE.small\n",
    "\n",
    "DATASET_SOURCE_TYPE = Enum('DATASET_SOURCE_TYPE', 'bq gcs')\n",
    "DATASET_SOURCE = DATASET_SOURCE_TYPE.bq\n",
    "\n",
    "CSV_SCHEMA = [\n",
    "      bigquery.SchemaField(\"label\", \"INTEGER\", mode='REQUIRED'),\n",
    "      bigquery.SchemaField(\"int1\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int2\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int3\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int4\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int5\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int6\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int7\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int8\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int9\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int10\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int11\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int12\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int13\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"cat1\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat2\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat3\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat4\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat5\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat6\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat7\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat8\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat9\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat10\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat11\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat12\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat13\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat14\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat15\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat16\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat17\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat18\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat19\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat20\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat21\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat22\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat23\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat24\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat25\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat26\", \"STRING\")\n",
    "  ]\n",
    "\n",
    "# See https://docs.google.com/spreadsheets/d/1s_QCP4dyO9L9QXVQu0TKrIi767kMwlr8SsfAX5UCNrw/edit#gid=118220263\n",
    "KEY_CROSSES = [\n",
    "  ['cat13','cat18'],\n",
    "  ['cat11', 'cat18'],\n",
    "  ['cat11', 'cat15'],\n",
    "  ['cat2', 'cat8'],\n",
    "  ['cat7', 'cat15'],\n",
    "  ['cat13', 'cat15'],\n",
    "  ['cat1', 'cat2'],\n",
    "  ['cat13', 'cat19'],\n",
    "  ['cat2', 'cat13'],\n",
    "  ['cat7', 'cat18'],\n",
    "  ['cat1', 'cat13'],\n",
    "  ['cat2', 'cat5'],\n",
    "  ['cat2', 'cat11'],\n",
    "  ['cat11', 'cat19'],\n",
    "  ['cat1', 'cat11'],\n",
    "  ['cat8', 'cat13']\n",
    "]\n",
    "\n",
    "def get_mean_and_std_dicts():\n",
    "  table_name = 'days' if DATASET_SIZE == DATASET_SIZE_TYPE.full else 'small'\n",
    "  client = bigquery.Client(project=PROJECT_ID)\n",
    "  query = \"\"\"\n",
    "    select\n",
    "    AVG(int1) as avg_int1, STDDEV(int1) as std_int1,\n",
    "    AVG(int2) as avg_int2, STDDEV(int2) as std_int2,\n",
    "    AVG(int3) as avg_int3, STDDEV(int3) as std_int3,\n",
    "    AVG(int4) as avg_int4, STDDEV(int4) as std_int4,\n",
    "    AVG(int5) as avg_int5, STDDEV(int5) as std_int5,\n",
    "    AVG(int6) as avg_int6, STDDEV(int6) as std_int6,\n",
    "    AVG(int7) as avg_int7, STDDEV(int7) as std_int7,\n",
    "    AVG(int8) as avg_int8, STDDEV(int8) as std_int8,\n",
    "    AVG(int9) as avg_int9, STDDEV(int9) as std_int9,\n",
    "    AVG(int10) as avg_int10, STDDEV(int10) as std_int10,\n",
    "    AVG(int11) as avg_int11, STDDEV(int11) as std_int11,\n",
    "    AVG(int12) as avg_int12, STDDEV(int12) as std_int12,\n",
    "    AVG(int13) as avg_int13, STDDEV(int13) as std_int13\n",
    "    from `alekseyv-scalableai-dev.criteo_kaggle.{table_name}`\n",
    "  \"\"\".format(table_name = table_name)\n",
    "  query_job = client.query(\n",
    "      query,\n",
    "      location=LOCATION,\n",
    "  )  # API request - starts the query\n",
    "\n",
    "  df = query_job.to_dataframe()\n",
    "\n",
    "  mean_dict = dict((field[0].replace('avg_', ''), df[field[0]][0]) for field in df.items() if field[0].startswith('avg'))\n",
    "  std_dict = dict((field[0].replace('std_', ''), df[field[0]][0]) for field in df.items() if field[0].startswith('std'))\n",
    "  return (mean_dict, std_dict)\n",
    "\n",
    "def get_vocabulary_size_dict():\n",
    "  table_name = 'days' if DATASET_SIZE == DATASET_SIZE_TYPE.full else 'small'\n",
    "  client = bigquery.Client(project=PROJECT_ID)\n",
    "  query = \"\"\"\n",
    "    SELECT\n",
    "    COUNT(DISTINCT cat1) as cat1,\n",
    "    COUNT(DISTINCT cat2) as cat2,\n",
    "    COUNT(DISTINCT cat3) as cat3,\n",
    "    COUNT(DISTINCT cat4) as cat4,\n",
    "    COUNT(DISTINCT cat5) as cat5,\n",
    "    COUNT(DISTINCT cat6) as cat6,\n",
    "    COUNT(DISTINCT cat7) as cat7,\n",
    "    COUNT(DISTINCT cat8) as cat8,\n",
    "    COUNT(DISTINCT cat9) as cat9,\n",
    "    COUNT(DISTINCT cat10) as cat10,\n",
    "    COUNT(DISTINCT cat11) as cat11,\n",
    "    COUNT(DISTINCT cat12) as cat12,\n",
    "    COUNT(DISTINCT cat13) as cat13,\n",
    "    COUNT(DISTINCT cat14) as cat14,\n",
    "    COUNT(DISTINCT cat15) as cat15,\n",
    "    COUNT(DISTINCT cat16) as cat16,\n",
    "    COUNT(DISTINCT cat17) as cat17,\n",
    "    COUNT(DISTINCT cat18) as cat18,\n",
    "    COUNT(DISTINCT cat19) as cat19,\n",
    "    COUNT(DISTINCT cat20) as cat20,\n",
    "    COUNT(DISTINCT cat21) as cat21,\n",
    "    COUNT(DISTINCT cat22) as cat22,\n",
    "    COUNT(DISTINCT cat23) as cat23,\n",
    "    COUNT(DISTINCT cat24) as cat24,\n",
    "    COUNT(DISTINCT cat25) as cat25,\n",
    "    COUNT(DISTINCT cat26) as cat26\n",
    "    FROM\n",
    "      `alekseyv-scalableai-dev.criteo_kaggle.{table_name}`\n",
    "  \"\"\".format(table_name = table_name)\n",
    "  query_job = client.query(\n",
    "      query,\n",
    "      location=LOCATION,\n",
    "  )  # API request - starts the query\n",
    "\n",
    "  df = query_job.to_dataframe()\n",
    "  dictionary = dict((field[0], df[field[0]][0]) for field in df.items())\n",
    "  return dictionary\n",
    "\n",
    "def get_corpus_dict():\n",
    "  table_name = 'days' if DATASET_SIZE == DATASET_SIZE_TYPE.full else 'small'\n",
    "  client = bigquery.Client(project=PROJECT_ID)\n",
    "  query = \"\"\"\n",
    "    select\n",
    "    cat_name,\n",
    "    cat_value,\n",
    "    cat_index\n",
    "    from `alekseyv-scalableai-dev.criteo_kaggle.{table_name}_corpus`\n",
    "  \"\"\".format(table_name = table_name)\n",
    "  query_job = client.query(\n",
    "      query,\n",
    "      location=\"US\",\n",
    "  )  # API request - starts the query\n",
    "\n",
    "  df = query_job.to_dataframe()\n",
    "  corpus = dict()\n",
    "  for _, row in df.iterrows():\n",
    "    cat_name = row[0]\n",
    "    cat_value = row[1]\n",
    "    cat_index = row[2]\n",
    "    if not cat_name in corpus:\n",
    "      corpus[cat_name] = dict()\n",
    "    if cat_value is None:\n",
    "      cat_value = ''\n",
    "    corpus[cat_name][cat_value] = cat_index\n",
    "  return corpus\n",
    "\n",
    "def corpus_to_lookuptable(corpus):\n",
    "  lookup_dict = dict()\n",
    "  for key, value in corpus.items():\n",
    "    initializer = tf.lookup.KeyValueTensorInitializer(\n",
    "      list(value.keys()),\n",
    "      list(value.values()),\n",
    "      key_dtype=tf.string,\n",
    "      value_dtype=tf.int64)\n",
    "    # cat_index in corpus starts with 1, reserving 0 for out of vocabulary values\n",
    "    lookup_table = tf.lookup.StaticHashTable(initializer, 0)\n",
    "    lookup_dict[key] = lookup_table\n",
    "  return lookup_dict\n",
    "\n",
    "def get_corpus():\n",
    "  if EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.manual or EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.vocabular:\n",
    "    return corpus_to_lookuptable(get_corpus_dict())\n",
    "  else:\n",
    "    return dict()\n",
    "\n",
    "# @tf.function is not really necessary here since function is used in tf.data pipeline\n",
    "# Use print(tf.autograph.to_code(transform_row.python_function)) to see code generated by AutoGraph\n",
    "@tf.function\n",
    "def transform_row(row_dict, mean_dict, std_dict, corpus):\n",
    "  dict_without_label = dict(row_dict)\n",
    "  label = dict_without_label.pop('label')\n",
    "  for field in CSV_SCHEMA:\n",
    "    if (field.name.startswith('int')):\n",
    "        # use normalized mean value if data is missing (value will be 0)\n",
    "        value = float(dict_without_label[field.name])\n",
    "        dict_without_label[field.name] = (value - mean_dict[field.name]) / std_dict[field.name]\n",
    "    elif field.name.startswith('cat'):\n",
    "      if EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.none:\n",
    "        dict_without_label.pop(field.name)\n",
    "      elif EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.manual:\n",
    "        cat = dict_without_label[field.name]\n",
    "        if cat is None:\n",
    "          cat = ''\n",
    "        cat_index = corpus[field.name].lookup(cat)\n",
    "        if cat_index is None:\n",
    "          tf.print('not found for {}'.format(field.name))\n",
    "          cat_index = tf.constant(-1)\n",
    "        dict_without_label[field.name] = cat_index\n",
    "  return (dict_without_label, label)\n",
    "\n",
    "def read_bigquery(table_name):\n",
    "  if DATASET_SIZE == DATASET_SIZE_TYPE.small:\n",
    "    table_name += '_small'\n",
    "\n",
    "  (mean_dict, std_dict) = get_mean_and_std_dicts()\n",
    "  corpus = get_corpus()\n",
    "  requested_streams_count = 10\n",
    "  tensorflow_io_bigquery_client = BigQueryClient()\n",
    "  read_session = tensorflow_io_bigquery_client.read_session(\n",
    "      \"projects/\" + PROJECT_ID,\n",
    "      PROJECT_ID, table_name, DATASET_ID,\n",
    "      list(field.name for field in CSV_SCHEMA),\n",
    "      list(dtypes.int64 if field.field_type == 'INTEGER'\n",
    "           else dtypes.string for field in CSV_SCHEMA),\n",
    "      requested_streams=requested_streams_count)\n",
    "\n",
    "  # manually sharding output instaead of using return read_session.parallel_read_rows()\n",
    "  streams = read_session.get_streams()\n",
    "  # streams_count = len(streams) # does not work for Estimator\n",
    "  streams_count = tf.size(streams)\n",
    "  streams_count64 = tf.cast(streams_count, dtype=tf.int64)\n",
    "  streams_ds = dataset_ops.Dataset.from_tensor_slices(streams).shuffle(buffer_size=streams_count64)\n",
    "  dataset = streams_ds.interleave(\n",
    "            read_session.read_rows,\n",
    "            cycle_length=streams_count64,\n",
    "            num_parallel_calls=streams_count64)\n",
    "\n",
    "  transform_row_function = lambda row: transform_row(row, mean_dict, std_dict, corpus)\n",
    "\n",
    "  transformed_ds = dataset\\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .shuffle(50) \\\n",
    "    .map (transform_row_function, num_parallel_calls=streams_count) \\\n",
    "    .prefetch(50)\n",
    "\n",
    "  # TODO: enable once tf.data.experimental.AutoShardPolicy.OFF is available\n",
    "  # Interleave dataset is not shardable, turning off sharding\n",
    "  # See https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding_and_batch_size\n",
    "  # Instead we are shuffling data.\n",
    "  # options = tf.data.Options()\n",
    "  #  options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "  # return transformed_ds.with_options(options)\n",
    "  return transformed_ds\n",
    "\n",
    "def transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus):\n",
    "    row_dict = dict(zip(list(field.name for field in CSV_SCHEMA) + ['row_hash'], list(row_tuple)))\n",
    "    row_dict.pop('row_hash')\n",
    "    return transform_row(row_dict, mean_dict, std_dict, corpus)\n",
    "\n",
    "\n",
    "def _get_file_names(file_pattern):\n",
    "  if isinstance(file_pattern, list):\n",
    "    if not file_pattern:\n",
    "      raise ValueError(\"File pattern is empty.\")\n",
    "    file_names = []\n",
    "    for entry in file_pattern:\n",
    "      file_names.extend(gfile.Glob(entry))\n",
    "  else:\n",
    "    file_names = list(gfile.Glob(file_pattern))\n",
    "\n",
    "  if not file_names:\n",
    "    raise ValueError(\"No files match %s.\" % file_pattern)\n",
    "  return file_names\n",
    "\n",
    "def read_gcs(table_name):\n",
    "  if DATASET_SIZE == DATASET_SIZE_TYPE.small:\n",
    "    table_name += '_small'\n",
    "  else:\n",
    "    table_name += '_full'\n",
    "\n",
    "  gcs_filename_glob = 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_from_bq/{}*'.format(table_name)\n",
    "  file_names = _get_file_names(gcs_filename_glob)\n",
    "  num_parallel_calls = max(10, len(file_names))\n",
    "  file_names_ds = dataset_ops.Dataset.from_tensor_slices(file_names).shuffle(buffer_size=20)\n",
    "  record_defaults = list(tf.int32 if field.name == 'label' else tf.constant(0, dtype=tf.int32) if field.name.startswith('int') else tf.constant('', dtype=tf.string) for field in CSV_SCHEMA) + [tf.string]\n",
    "  dataset = file_names_ds.interleave(\n",
    "          lambda file_name: tf.data.experimental.CsvDataset(file_name, record_defaults, field_delim='\\t', header=False),\n",
    "          cycle_length=num_parallel_calls,\n",
    "          num_parallel_calls=num_parallel_calls)\n",
    "\n",
    "  corpus = get_corpus()\n",
    "  (mean_dict, std_dict) = get_mean_and_std_dicts()\n",
    "  transofrom_row_gcs_function = lambda *row_tuple: transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus)\n",
    "\n",
    "  transformed_ds = dataset\\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .shuffle(50) \\\n",
    "    .map (transofrom_row_gcs_function, num_parallel_calls=num_parallel_calls) \\\n",
    "    .prefetch(50)\n",
    "  return transformed_ds\n",
    "\n",
    "def get_dataset(table_name):\n",
    "  global DATASET_SOURCE\n",
    "  return read_gcs(table_name) if DATASET_SOURCE == DATASET_SOURCE_TYPE.gcs else read_bigquery(table_name)\n",
    "\n",
    "def get_max_steps():\n",
    "  dataset_size = FULL_TRAIN_DATASET_SIZE if DATASET_SIZE == DATASET_SIZE_TYPE.full else SMALL_TRAIN_DATASET_SIZE\n",
    "  return EPOCHS * dataset_size // BATCH_SIZE\n",
    "\n",
    "def create_categorical_feature_column_with_hash_bucket(corpus_dict, key):\n",
    "  corpus_size = len(corpus_dict[key])\n",
    "  hash_bucket_size = min(corpus_size, 100000)\n",
    "  categorical_feature_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key,\n",
    "    hash_bucket_size,\n",
    "    dtype=tf.dtypes.string\n",
    "  )\n",
    "  logging.info('categorical column %s hash_bucket_size %d', key, hash_bucket_size)\n",
    "  return categorical_feature_column\n",
    "\n",
    "def create_categorical_feature_column_with_vocabulary_list(corpus_dict, key):\n",
    "  corpus_size = len(corpus_dict[key])\n",
    "  categorical_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key,\n",
    "    list(corpus_dict[key].keys()),\n",
    "    dtype=tf.dtypes.string,\n",
    "    num_oov_buckets=corpus_size\n",
    "  )\n",
    "  logging.info('categorical column with vocabular %s corpus_size %d', key, corpus_size)\n",
    "\n",
    "  return categorical_feature_column\n",
    "\n",
    "def create_embedding(corpus_dict, key, categorical_feature_column):\n",
    "  corpus_size = len(corpus_dict[key])\n",
    "  if corpus_size < 10:\n",
    "    logging.info('categorical column %s corpus_size %d - creating indicator column', key, corpus_size)\n",
    "    return tf.feature_column.indicator_column(categorical_feature_column)\n",
    "\n",
    "  embedding_dimension = int(min(50, math.floor(6 * corpus_size**0.25)))\n",
    "  embedding_feature_column = tf.feature_column.embedding_column(\n",
    "      categorical_feature_column,\n",
    "      embedding_dimension)\n",
    "  return embedding_feature_column\n",
    "\n",
    "def create_linear_feature_columns():\n",
    "  return list(tf.feature_column.numeric_column(field.name, dtype=tf.dtypes.float32)  for field in CSV_SCHEMA if field.field_type == 'INTEGER' and field.name != 'label')\n",
    "\n",
    "def create_categorical_embeddings_feature_columns(corpus_dict):\n",
    "  if EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.none:\n",
    "    return []\n",
    "  elif EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.hashbucket:\n",
    "    return list(create_embedding(\n",
    "      corpus_dict,\n",
    "      key,\n",
    "      create_categorical_feature_column_with_hash_bucket(corpus_dict, key))\n",
    "        for key, _ in corpus_dict.items())\n",
    "  elif EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.vocabular:\n",
    "    return list(create_embedding(\n",
    "      corpus_dict,\n",
    "      key,\n",
    "      create_categorical_feature_column_with_vocabulary_list(corpus_dict, key))\n",
    "        for key, _ in corpus_dict.items())\n",
    "  else:\n",
    "    raise ValueError('invalid EMBEDDINGS_MODE: {}'.format(EMBEDDINGS_MODE))\n",
    "\n",
    "def create_feature_columns():\n",
    "  corpus_dict = get_corpus_dict()\n",
    "  feature_columns = []\n",
    "  feature_columns.extend(create_linear_feature_columns())\n",
    "  feature_columns.extend(create_categorical_embeddings_feature_columns(corpus_dict))\n",
    "  return feature_columns\n",
    "\n",
    "def create_input_layer():\n",
    "    numeric_feature_columns = create_linear_feature_columns()\n",
    "    numerical_input_layers = {\n",
    "       feature_column.name: tf.keras.layers.Input(name=feature_column.name, shape=(1,), dtype=tf.float32)\n",
    "       for feature_column in numeric_feature_columns\n",
    "    }\n",
    "    categorical_feature_columns = create_categorical_embeddings_feature_columns()\n",
    "    categorical_input_layers = {\n",
    "       feature_column.categorical_column.name: tf.keras.layers.Input(name=feature_column.categorical_column.name, shape=(), dtype=tf.string)\n",
    "       for feature_column in categorical_feature_columns\n",
    "    }\n",
    "    input_layers = numerical_input_layers.copy()\n",
    "    input_layers.update(categorical_input_layers)\n",
    "\n",
    "    return (input_layers, numeric_feature_columns + categorical_feature_columns)\n",
    "\n",
    "def create_embedding_from_input(corpus_dict, name, input_layer):\n",
    "  size = len(corpus_dict[name]) + 2\n",
    "  dimension =  int(min(50, math.floor(6 * size**0.25)))\n",
    "  logging.info('embedding name:{} size:{} dim:{}'.format(name, size, dimension))\n",
    "  embedding = tf.keras.layers.Embedding(size, dimension, name = name + '_embedding', input_length=1)(input_layer)\n",
    "  return embedding\n",
    "\n",
    "def create_keras_model_functional():\n",
    "    (feature_layer_inputs, feature_columns) = create_input_layer()\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
    "    x = tf.keras.layers.Dense(2560, activation=tf.nn.relu)(feature_layer_outputs)\n",
    "    x = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "    inputs=[v for v in feature_layer_inputs.values()]\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile Keras model\n",
    "    model.compile(\n",
    "      # cannot use Adagrad with mirroredstartegy https://github.com/tensorflow/tensorflow/issues/19551\n",
    "      optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      #optimizer=tf.optimizers.Adam(),\n",
    "      #optimizer=tf.optimizers.Adagrad(),\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=['accuracy'])\n",
    "    logging.info(\"model: \" + str(model.summary()))\n",
    "    return model\n",
    "\n",
    "def create_keras_model_functional_no_feature_layer():\n",
    "  corpus_dict = get_corpus_dict()\n",
    "  categorical_input_with_names = list((field.name, tf.keras.layers.Input(shape=[1], name = field.name, dtype=tf.int32))\n",
    "    for field in CSV_SCHEMA if field.field_type == 'STRING' and field.name != 'label')\n",
    "  categorical_inputs = list(input_layer\n",
    "    for (name, input_layer) in categorical_input_with_names)\n",
    "  categorical_embeddings = list(create_embedding_from_input(corpus_dict, name, input_layer)\n",
    "    for (name, input_layer) in categorical_input_with_names)\n",
    "\n",
    "  numerical_inputs = list(tf.keras.layers.Input(shape=[1], name = field.name, dtype=tf.float32)\n",
    "    for field in CSV_SCHEMA if field.field_type == 'INTEGER' and field.name != 'label')\n",
    "\n",
    "  categorical_combined = tf.keras.layers.concatenate(categorical_embeddings)\n",
    "  x = tf.keras.layers.Flatten()(categorical_combined)\n",
    "  x = tf.keras.layers.concatenate([x] + numerical_inputs)\n",
    "  x = tf.keras.layers.Dense(2560, activation=tf.nn.relu)(x)\n",
    "  x = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "  x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x)\n",
    "\n",
    "  outputs = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "  model = tf.keras.Model(inputs=categorical_inputs + numerical_inputs, outputs=outputs)\n",
    "\n",
    "  # Compile Keras model\n",
    "  model.compile(\n",
    "    # cannot use Adagrad with mirroredstartegy https://github.com/tensorflow/tensorflow/issues/19551\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "    #optimizer=tf.optimizers.Adam(),\n",
    "    #optimizer=tf.optimizers.Adagrad(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "  logging.info(\"model: \" + str(model.summary()))\n",
    "\n",
    "  return model\n",
    "\n",
    "def create_keras_model_functional_wide_and_deep_dontuse():\n",
    "    (feature_layer_inputs, feature_columns) = create_input_layer()\n",
    "    categorical_feature_columns=create_categorical_embeddings_feature_columns()\n",
    "\n",
    "    wide = tf.keras.layers.DenseFeatures(categorical_feature_columns)(feature_layer_inputs)\n",
    "\n",
    "    deep = tf.keras.layers.DenseFeatures(feature_columns)(feature_layer_inputs)\n",
    "    deep = tf.keras.layers.Dense(2560, activation=tf.nn.relu)(deep)\n",
    "    deep = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(deep)\n",
    "    deep = tf.keras.layers.Dense(256, activation=tf.nn.relu)(deep)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(\n",
    "      tf.keras.layers.concatenate([deep, wide]))\n",
    "\n",
    "    outputs = tf.squeeze(outputs, -1)\n",
    "    inputs=[v for v in feature_layer_inputs.values()]\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile Keras model\n",
    "    model.compile(\n",
    "      # cannot use Adagrad with mirroredstartegy https://github.com/tensorflow/tensorflow/issues/19551\n",
    "      #optimizer=tf.optimizers.Adagrad(learning_rate=0.05),\n",
    "      optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=['accuracy'])\n",
    "    logging.info(\"model: \" + str(model.summary()))\n",
    "    return model\n",
    "\n",
    "def create_keras_model_sequential_wide_and_deep():\n",
    "    if EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.none:\n",
    "      raise ValueError('embeddings are required for wide and deep model')\n",
    "\n",
    "    linear_feature_columns = create_linear_feature_columns()\n",
    "    corpus_dict = get_corpus_dict()\n",
    "    categorical_feature_columns_and_embeddings = create_categorical_embeddings_feature_columns(corpus_dict)\n",
    "    categorical_feature_columns = list(tf.feature_column.indicator_column(embedding.categorical_column) for embedding in categorical_feature_columns_and_embeddings)\n",
    "    embeddings = list(embedding for embedding in categorical_feature_columns_and_embeddings)\n",
    "\n",
    "    crossed_columns = list(tf.feature_column.indicator_column(tf.feature_column.crossed_column(\n",
    "      keys,\n",
    "      min(max(len(corpus_dict[keys[0]]), len(corpus_dict[keys[1]])), 100000))) for keys in KEY_CROSSES)\n",
    "\n",
    "    deep_model_feature_columns = embeddings + linear_feature_columns\n",
    "    dense_feature_layer = tf.keras.layers.DenseFeatures(deep_model_feature_columns)\n",
    "    Dense = tf.keras.layers.Dense\n",
    "    dense_model = tf.keras.Sequential(\n",
    "    [\n",
    "        dense_feature_layer,\n",
    "        Dense(2560, activation=tf.nn.relu),\n",
    "        Dense(1024, activation=tf.nn.relu),\n",
    "        Dense(256, activation=tf.nn.relu),\n",
    "        Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "    wide_model_feature_columns = categorical_feature_columns + crossed_columns\n",
    "    # no sparse alternative, see https://github.com/tensorflow/community/pull/188/\n",
    "    # https://cs/piper///depot/google3/learning/tfx/users/tfx/examples/tfx_keras_widedeep/models/premade_widedeep/model.py;rcl=291050847;l=100\n",
    "    sparse_feature_layer = tf.keras.layers.DenseFeatures(wide_model_feature_columns)\n",
    "\n",
    "    linear_model = tf.keras.Sequential(\n",
    "    [\n",
    "      sparse_feature_layer,\n",
    "      Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "    wide_deep_model = tf.keras.experimental.WideDeepModel(linear_model, dense_model)\n",
    "    #wide_deep_model(deep_model_feature_columns) # todo change\n",
    "    linear_opt = tf.keras.optimizers.RMSprop()\n",
    "    dnn_opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "    wide_deep_model.compile(\n",
    "        optimizer=[linear_opt, dnn_opt],\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return wide_deep_model\n",
    "\n",
    "def create_keras_model_sequential():\n",
    "  feature_columns = create_feature_columns()\n",
    "\n",
    "  feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name=\"feature_layer\")\n",
    "  Dense = tf.keras.layers.Dense\n",
    "  model = tf.keras.Sequential(\n",
    "  [\n",
    "      feature_layer,\n",
    "      Dense(2560, activation=tf.nn.relu),\n",
    "      Dense(1024, activation=tf.nn.relu),\n",
    "      Dense(256, activation=tf.nn.relu),\n",
    "      Dense(1, activation=tf.nn.sigmoid)\n",
    "  ])\n",
    "\n",
    "  logging.info('compiling sequential keras model')\n",
    "  # Compile Keras model\n",
    "  model.compile(\n",
    "      # cannot use Adagrad with mirroredstartegy https://github.com/tensorflow/tensorflow/issues/19551\n",
    "      #optimizer=tf.optimizers.Adagrad(learning_rate=0.05),\n",
    "      optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train_and_evaluate_keras_model(model, model_dir):\n",
    "  dataset_size = FULL_TRAIN_DATASET_SIZE if DATASET_SIZE == DATASET_SIZE_TYPE.full else SMALL_TRAIN_DATASET_SIZE\n",
    "  logging.info('training datset size: {}'.format(dataset_size))\n",
    "  training_ds = get_dataset('train')\n",
    "\n",
    "  #log_dir= os.path.join(model_dir, \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  log_dir= os.path.join(model_dir, \"logs\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    embeddings_freq=1,\n",
    "    profile_batch=min(EPOCHS, 2))\n",
    "\n",
    "  checkpoints_dir= os.path.join(model_dir, \"checkpoints\")\n",
    "  # crashing https://github.com/tensorflow/tensorflow/issues/27688\n",
    "  if not os.path.exists(checkpoints_dir):\n",
    "      os.makedirs(checkpoints_dir)\n",
    "\n",
    "  callbacks=[]\n",
    "  train_time_callback = TrainTimeCallback()\n",
    "  batch_summary_callback = BatchAccuracyAndLossSummaryCallback(log_dir, DATASET_SIZE)\n",
    "\n",
    "  if DISTRIBUTION_STRATEGY_TYPE == 'tf.distribute.experimental.TPUStrategy':\n",
    "    # epoch and accuracy constants are not supported when training on TPU.\n",
    "    checkpoints_file_path = checkpoints_dir + \"/epochs_tpu.hdf5\"\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoints_file_path, verbose=1, mode='max')\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback, train_time_callback]\n",
    "  else:\n",
    "    if EMBEDDINGS_MODE == EMBEDDINGS_MODE_TYPE.manual or DISTRIBUTION_STRATEGY_TYPE == 'tf.distribute.experimental.MultiWorkerMirroredStrategy':\n",
    "      # accuracy fails for adagrad\n",
    "      # for some reason accuracy is not available for EMBEDDINGS_MODE_TYPE.manual\n",
    "      # for some reason accuracy is not available for MultiWorkerMirroredStrategy\n",
    "      checkpoints_file_path = checkpoints_dir + \"/epochs:{epoch:03d}.hdf5\"\n",
    "    else:\n",
    "      checkpoints_file_path = checkpoints_dir + \"/epochs:{epoch:03d}-accuracy:{accuracy:.3f}.hdf5\"\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoints_file_path, verbose=1, mode='max')\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback, batch_summary_callback, train_time_callback]\n",
    "    #callbacks=[tensorboard_callback, checkpoint_callback, train_time_callback]\n",
    "\n",
    "  verbosity = 1 if TRAIN_LOCATION == TRAIN_LOCATION_TYPE.local else 2\n",
    "  logging.info('training keras model')\n",
    "  model.fit(training_ds, epochs=EPOCHS, verbose=verbosity, callbacks=callbacks)\n",
    "  eval_ds = get_dataset('test')\n",
    "  logging.info(\"done training keras model, evaluating model\")\n",
    "  loss, accuracy = model.evaluate(eval_ds, verbose=verbosity, callbacks=[tensorboard_callback, batch_summary_callback])\n",
    "  logging.info(\"Eval - Loss: {}, Accuracy: {}\".format(loss, accuracy))\n",
    "  logging.info(model.summary())\n",
    "  logging.info(\"done evaluating keras model\")\n",
    "\n",
    "def train_keras_model_to_estimator(strategy, model, model_dir):\n",
    "    logging.info('training for {} steps'.format(get_max_steps()))\n",
    "    config = tf.estimator.RunConfig(\n",
    "            train_distribute=strategy,\n",
    "            eval_distribute=strategy)\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model=model, model_dir=model_dir, config=config)\n",
    "    # Need to specify both max_steps and epochs. Each worker will go through epoch separately.\n",
    "    # see https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate?version=stable\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        keras_estimator,\n",
    "        train_spec=tf.estimator.TrainSpec(input_fn=lambda: get_dataset('train').repeat(EPOCHS), max_steps=get_max_steps()),\n",
    "        eval_spec=tf.estimator.EvalSpec(input_fn=lambda: get_dataset('test')))\n",
    "\n",
    "def train_keras_sequential(strategy, model_dir):\n",
    "  train_and_evaluate_keras_model(create_keras_model_sequential(), model_dir)\n",
    "\n",
    "def train_keras_functional(strategy, model_dir):\n",
    "  train_and_evaluate_keras_model(create_keras_model_functional(), model_dir)\n",
    "\n",
    "def train_keras_functional_no_feature_layer(strategy, model_dir):\n",
    "  train_and_evaluate_keras_model(create_keras_model_functional_no_feature_layer(), model_dir)\n",
    "\n",
    "def train_keras_functional_wide_and_deep(strategy, model_dir):\n",
    "  train_and_evaluate_keras_model(create_keras_model_functional_wide_and_deep(), model_dir)\n",
    "\n",
    "def train_keras_sequential_wide_and_deep(strategy, model_dir):\n",
    "  train_and_evaluate_keras_model(create_keras_model_sequential_wide_and_deep(), model_dir)\n",
    "\n",
    "def train_keras_to_estimator_sequential(strategy, model_dir):\n",
    "  train_keras_model_to_estimator(strategy, create_keras_model_sequential(), model_dir)\n",
    "\n",
    "def train_keras_to_estimator_functional(strategy, model_dir):\n",
    "  train_keras_model_to_estimator(strategy, create_keras_model_functional(), model_dir)\n",
    "\n",
    "def train_estimator(strategy, model_dir):\n",
    "  logging.info('training for {} steps'.format(get_max_steps()))\n",
    "  config = tf.estimator.RunConfig(\n",
    "          train_distribute=strategy,\n",
    "          eval_distribute=strategy)\n",
    "  feature_columns = create_feature_columns()\n",
    "  estimator = tf.estimator.DNNClassifier(\n",
    "      optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      feature_columns=feature_columns,\n",
    "      hidden_units=[2560, 1024, 256],\n",
    "      model_dir=model_dir,\n",
    "      config=config,\n",
    "      n_classes=2)\n",
    "  logging.info('training and evaluating estimator model')\n",
    "  # Need to specify both max_steps and epochs. Each worker will go through epoch separately.\n",
    "  # see https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate?version=stable\n",
    "  tf.estimator.train_and_evaluate(\n",
    "      estimator,\n",
    "      train_spec=tf.estimator.TrainSpec(input_fn=lambda: get_dataset('train').repeat(EPOCHS), max_steps=get_max_steps()),\n",
    "      eval_spec=tf.estimator.EvalSpec(input_fn=lambda: get_dataset('test')))\n",
    "  logging.info('done evaluating estimator model')\n",
    "\n",
    "def train_estimator_wide_and_deep(strategy, model_dir):\n",
    "  logging.info('training for {} steps'.format(get_max_steps()))\n",
    "  config = tf.estimator.RunConfig(\n",
    "          train_distribute=strategy,\n",
    "          eval_distribute=strategy)\n",
    "\n",
    "  linear_feature_columns = create_linear_feature_columns()\n",
    "  corpus_dict = get_corpus_dict()\n",
    "  categorical_feature_columns_and_embeddings = create_categorical_embeddings_feature_columns(corpus_dict)\n",
    "  categorical_feature_columns = list(tf.feature_column.indicator_column(embedding.categorical_column) for embedding in categorical_feature_columns_and_embeddings)\n",
    "  embeddings = list(embedding for embedding in categorical_feature_columns_and_embeddings)\n",
    "\n",
    "  crossed_columns = list(tf.feature_column.indicator_column(tf.feature_column.crossed_column(\n",
    "    keys,\n",
    "    min(max(len(corpus_dict[keys[0]]), len(corpus_dict[keys[1]])), 100000))) for keys in KEY_CROSSES)\n",
    "\n",
    "  deep_model_feature_columns = embeddings + linear_feature_columns\n",
    "  wide_model_feature_columns = categorical_feature_columns + crossed_columns\n",
    "  estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "      dnn_optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      linear_optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "      linear_feature_columns=wide_model_feature_columns,\n",
    "      dnn_feature_columns=deep_model_feature_columns,\n",
    "      dnn_hidden_units=[2560, 1024, 256],\n",
    "      model_dir=model_dir,\n",
    "      config=config,\n",
    "      n_classes=2)\n",
    "  logging.info('training wide and deep estimator model')\n",
    "  # Need to specify both max_steps and epochs. Each worker will go through epoch separately.\n",
    "  # see https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate?version=stable\n",
    "  tf.estimator.train_and_evaluate(\n",
    "      estimator,\n",
    "      train_spec=tf.estimator.TrainSpec(input_fn=lambda: get_dataset('train').repeat(EPOCHS), max_steps=get_max_steps()),\n",
    "      eval_spec=tf.estimator.EvalSpec(input_fn=lambda: get_dataset('test')))\n",
    "  logging.info('done evaluating wide and deep estimator model')\n",
    "\n",
    "def train_custom_loop_keras_sequential(strategy, model_dir):\n",
    "  train_custom_loop(strategy, create_keras_model_sequential(), model_dir)\n",
    "\n",
    "def train_custom_loop_keras_model_functional_no_feature_layer(strategy, model_dir):\n",
    "  train_custom_loop(strategy, create_keras_model_functional_no_feature_layer(), model_dir)\n",
    "\n",
    "def train_custom_loop(strategy, model, model_dir):\n",
    "  logging.info('training using custom loop')\n",
    "\n",
    "  log_dir= os.path.join(model_dir, \"logs\")\n",
    "  if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "  # This is fine for MirroredStrategy and TPUStrategy, but has to be changed to run on chief only\n",
    "  # once multi-node training is supported (ParameterServer, MultiWorkerMirroredStrategy).\n",
    "  batch_summary_callback = BatchAccuracyAndLossSummaryCallback(DATASET_SIZE)\n",
    "  train_time_callback = TrainTimeCallback()\n",
    "  checkpoints_dir= os.path.join(model_dir, \"checkpoints\")\n",
    "  if not os.path.exists(checkpoints_dir):\n",
    "      os.makedirs(checkpoints_dir)\n",
    "\n",
    "  checkpoints_file_path = checkpoints_dir + \"/epochs:{epoch:03d}.hdf5\"\n",
    "\n",
    "  loss_object = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "  loss_fn = lambda labels, predictions: tf.reduce_mean(loss_object(labels, predictions))\n",
    "\n",
    "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "  train_accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "      name='train_accuracy')\n",
    "  test_accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "      name='test_accuracy')\n",
    "  optimizer = tf.optimizers.SGD(learning_rate=0.05)\n",
    "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(examples, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(examples, training=True)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    loss = loss_fn(labels, predictions)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "    test_loss.update_state(loss)\n",
    "    return loss\n",
    "\n",
    "  train_dist_dataset = get_dataset('train')\n",
    "  train_time_callback.on_train_begin()\n",
    "  for epoch in range(EPOCHS):\n",
    "    batch_summary_callback.on_epoch_begin(epoch, {})\n",
    "    train_time_callback.on_epoch_begin(epoch, {})\n",
    "\n",
    "    # TRAIN LOOP\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for (examples, labels) in train_dist_dataset:\n",
    "      # batch losses from all replicas\n",
    "      batch_loss_all_replicas = strategy.experimental_run_v2(train_step, args=(examples, labels))\n",
    "      # reduced to a single number both across replicas and across the bacth size\n",
    "      loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, batch_loss_all_replicas, axis=None)\n",
    "      total_loss += loss\n",
    "      train_loss = total_loss / num_batches\n",
    "      batch_summary_callback.on_train_batch_end(\n",
    "        num_batches,\n",
    "        {'accuracy': train_accuracy.result(),\n",
    "        'loss': train_loss })\n",
    "      num_batches += 1\n",
    "    checkpoint.save(checkpoints_file_path.format(epoch=epoch))\n",
    "    train_time_callback.params = {'steps' : num_batches}\n",
    "    train_time_callback.on_epoch_end(epoch, {})\n",
    "    logging.info(\"Epoch: {} - Loss: {}, Accuracy: {}\".format(epoch, loss, train_accuracy.result()))\n",
    "  train_time_callback.on_train_end()\n",
    "\n",
    "  test_dist_dataset = get_dataset('test')\n",
    "\n",
    "  # Keras evaluation\n",
    "  # logging.info(\"done training keras model, evaluating model\")\n",
    "  # verbosity = 1 if TRAIN_LOCATION == TRAIN_LOCATION_TYPE.local else 2\n",
    "  # loss, accuracy = model.evaluate(test_dist_dataset, verbose=verbosity)\n",
    "  # logging.info(\"Eval - Loss: {}, Accuracy: {}\".format(loss, accuracy))\n",
    "\n",
    "  # TEST LOOP\n",
    "  for (examples, labels) in test_dist_dataset:\n",
    "    batch_loss_all_replicas = strategy.experimental_run_v2(test_step, args=(examples, labels))\n",
    "\n",
    "  logging.info(\"Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(\n",
    "    train_loss,\n",
    "    train_accuracy.result(),\n",
    "    test_loss.result(),\n",
    "    test_accuracy.result()))\n",
    "\n",
    "  test_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Define the task arguments with the default values.\n",
    "    Returns:\n",
    "        experiment parameters\n",
    "    \"\"\"\n",
    "    args_parser = argparse.ArgumentParser()\n",
    "    args_parser.add_argument(\n",
    "        '--train-location',\n",
    "        help='where to train model - locally or in the cloud',\n",
    "        choices=TRAIN_LOCATION_TYPE_VALUES.split(' '),\n",
    "        default='local')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--model-name',\n",
    "        help='model name, not used.')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='folder or GCS location to write checkpoints and export models.',\n",
    "        required=True)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--distribution-strategy',\n",
    "        help='Distribution strategy to use.',\n",
    "        choices=DISTRIBUTION_STRATEGY_TYPE_VALUES.split(' '))\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--training-function',\n",
    "        help='Training function.',\n",
    "        choices=TRAINING_FUNCTION_VALUES.split(' '),\n",
    "        default='train_keras_sequential')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--batch-size',\n",
    "        help='Batch size for each training and evaluation step.',\n",
    "        type=int,\n",
    "        default=128)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--dataset-size',\n",
    "        help='Size of training set',\n",
    "        choices=['full', 'small'],\n",
    "        default='small')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--dataset-source',\n",
    "        help='Dataset source.',\n",
    "        choices=['bq', 'gcs'],\n",
    "        default='bq')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        help='Maximum number of training data epochs on which to train.',\n",
    "        default=2,\n",
    "        type=int)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--embeddings-mode',\n",
    "        help='Embeddings mode.',\n",
    "        choices=EMBEDDINGS_MODE_TYPE_VALUES,\n",
    "        default='hashbucket')\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--tensorboard',\n",
    "        action='store_true',\n",
    "        help='Ignored by this script.',\n",
    "        default=False)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--ai-platform-mode',\n",
    "        help='Ignored by this script.',\n",
    "        default=None)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--image-name',\n",
    "        help='Ignored by this script.',\n",
    "        default=None)\n",
    "\n",
    "    args_parser.add_argument(\n",
    "        '--no-gpu',\n",
    "        action='store_true',\n",
    "        help='Disabling GPUs - forces training to happen on CPU.',\n",
    "        default=False)\n",
    "\n",
    "    return args_parser.parse_args()\n",
    "\n",
    "def setup_environment(args):\n",
    "  global TRAIN_LOCATION\n",
    "  os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = GOOGLE_APPLICATION_CREDENTIALS\n",
    "  os.environ['PROJECT_ID'] = PROJECT_ID\n",
    "\n",
    "  TF_CONFIG = os.environ.get('TF_CONFIG')\n",
    "  if (TRAIN_LOCATION == TRAIN_LOCATION_TYPE.local):\n",
    "    # see https://stackoverflow.com/questions/58868459/tensorflow-assertionerror-on-fit-method\n",
    "    logging.warning('training locally')\n",
    "    if TF_CONFIG:\n",
    "      logging.warning('removing TF_CONFIG')\n",
    "      os.environ.pop('TF_CONFIG')\n",
    "  else:\n",
    "    logging.warning('training in cloud')\n",
    "    os.system('gsutil cp {}/{} .'.format(GOOGLE_APPLICATION_CREDENTIALS_GCS_BUCKET, GOOGLE_APPLICATION_CREDENTIALS))\n",
    "    os.environ[ 'GOOGLE_APPLICATION_CREDENTIALS'] = os.getcwd() + '/' + GOOGLE_APPLICATION_CREDENTIALS\n",
    "\n",
    "  if TF_CONFIG and '\"master\"' in TF_CONFIG and args.distribution_strategy:\n",
    "    # If distribution strategy is not set, don't replace 'master' -> 'chief',\n",
    "    # otherwise system will assume that environment works in distributed setting and\n",
    "    # will expect to be executed in distribution strategy scope.\n",
    "    # See b/147248890 and\n",
    "    # https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/distribute/multi_worker_util.py#L235\n",
    "    # Fixed in TF2.1rc2 https://github.com/tensorflow/tensorflow/commit/0390084145761a1d4da3be2bec8c56a28399db14\n",
    "    logging.warning('TF_CONFIG before modification:' + str(os.environ['TF_CONFIG']))\n",
    "    TF_CONFIG = TF_CONFIG.replace('\"master\"', '\"chief\"')\n",
    "    os.environ['TF_CONFIG'] = TF_CONFIG\n",
    "\n",
    "  if TF_CONFIG:\n",
    "    logging.warning('TF_CONFIG from env:' + str(os.environ['TF_CONFIG']))\n",
    "\n",
    "def main():\n",
    "    global BATCH_SIZE\n",
    "    global EPOCHS\n",
    "    global TRAIN_LOCATION\n",
    "    global DATASET_SOURCE\n",
    "    global DATASET_SIZE\n",
    "    global DISTRIBUTION_STRATEGY_TYPE\n",
    "    global EMBEDDINGS_MODE\n",
    "    args = get_args()\n",
    "\n",
    "    TRAIN_LOCATION = TRAIN_LOCATION_TYPE[args.train_location]\n",
    "    logging.info('train_location: ' + str(TRAIN_LOCATION))\n",
    "\n",
    "    if TRAIN_LOCATION != TRAIN_LOCATION_TYPE.local:\n",
    "      logging_client = google.cloud.logging.Client()\n",
    "      logging_client.setup_logging()\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info('>>>>>>>>>>>>>>>>>>> trainer started <<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    logging.info('trainer called with following arguments:')\n",
    "    logging.info(' '.join(sys.argv))\n",
    "\n",
    "    if args.no_gpu:\n",
    "      os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "      logging.info('forcing no GPU')\n",
    "\n",
    "    logging.warning('tf version: ' + tf.version.VERSION)\n",
    "\n",
    "    # Uncomment to see environment variables\n",
    "    # logging.warning(os.system('env'))\n",
    "\n",
    "    # Uncomment this line to see Op device placement\n",
    "    # tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    # https://github.com/tensorflow/tensorflow/issues/34568\n",
    "    # https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy\n",
    "    # Currently there is a limitation in MultiWorkerMirroredStrategy where TensorFlow ops need to be created after the instance of strategy is created.\n",
    "    distribution_strategy = None\n",
    "    # TPU won't work on this sample because strings are not supported by TPU, see:\n",
    "    # https://cloud.google.com/tpu/docs/troubleshooting#unsupported_data_type\n",
    "    if args.distribution_strategy == 'tf.distribute.experimental.TPUStrategy':\n",
    "      tpu = None\n",
    "      try:\n",
    "        logging.info('resolving to TPU cluster')\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        logging.info('connecting to TPU cluster')\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "      except ValueError as e:\n",
    "        logging.info('error connecting to TPU cluster: %s', e)\n",
    "        return\n",
    "      logging.info('initializing TPU system')\n",
    "      tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "      distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "      logging.info('training using TPUStrategy, tpu.cluster_spec: %s', tpu.cluster_spec())\n",
    "    elif args.distribution_strategy == 'tf.distribute.OneDeviceStrategy':\n",
    "      if args.no_gpu:\n",
    "        distribution_strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "      else:\n",
    "        distribution_strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    elif args.distribution_strategy:\n",
    "      distribution_strategy = eval(args.distribution_strategy)()\n",
    "\n",
    "    logging.info('tensorflow version: ' + tf.version.VERSION)\n",
    "    logging.info('tensorflow_io version: ' + tf_io.version.VERSION)\n",
    "    logging.info('device_lib.list_local_devices(): ' + str(device_lib.list_local_devices()))\n",
    "\n",
    "    DATASET_SOURCE = DATASET_SOURCE_TYPE[args.dataset_source]\n",
    "    logging.info('dataset_source: ' + str(DATASET_SOURCE))\n",
    "    DATASET_SIZE = DATASET_SIZE_TYPE[args.dataset_size]\n",
    "    logging.info('dataset_size: ' + str(DATASET_SIZE))\n",
    "    DISTRIBUTION_STRATEGY_TYPE = args.distribution_strategy\n",
    "    logging.info('distribution_strategy: ' + str(DISTRIBUTION_STRATEGY_TYPE))\n",
    "\n",
    "    model_dir = args.job_dir\n",
    "    # if TRAIN_LOCATION == TRAIN_LOCATION_TYPE.cloud and os.environ.get('HOSTNAME'):\n",
    "    #   model_dir = os.path.join(model_dir, os.environ.get('HOSTNAME'))\n",
    "    # model_dir = os.path.join(model_dir, args.training_function, 'model.joblib')\n",
    "    logging.info('Model will be saved to \"%s...\"', model_dir)\n",
    "\n",
    "    logging.info('training_function arg: ' + str(args.training_function))\n",
    "    training_function = getattr(sys.modules[__name__], args.training_function)\n",
    "    logging.info('training_function: ' + str(training_function))\n",
    "\n",
    "    EMBEDDINGS_MODE = EMBEDDINGS_MODE_TYPE[args.embeddings_mode]\n",
    "    if args.training_function == 'train_keras_functional_no_feature_layer':\n",
    "      EMBEDDINGS_MODE = EMBEDDINGS_MODE_TYPE.manual\n",
    "    logging.info('embeddings_mode: ' + str(EMBEDDINGS_MODE))\n",
    "\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    EPOCHS = args.num_epochs\n",
    "\n",
    "    setup_environment(args)\n",
    "\n",
    "    if not args.distribution_strategy:\n",
    "      logging.info('no distribution_strategy')\n",
    "      training_function(None, model_dir)\n",
    "    else:\n",
    "      if 'estimator' in args.training_function:\n",
    "        logging.info('args.training_function:' + args.training_function)\n",
    "        logging.info('distribution_strategy not in scope: ' + str(type(distribution_strategy)))\n",
    "        training_function(distribution_strategy, model_dir)\n",
    "      else:\n",
    "        with distribution_strategy.scope():\n",
    "          logging.info('distribution_strategy in scope: ' + str(type(distribution_strategy)))\n",
    "          training_function(distribution_strategy, model_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "TRAIN_LOCATION = TRAIN_LOCATION_TYPE.local\n",
    "DATASET_SOURCE = DATASET_SOURCE_TYPE.bq\n",
    "DATASET_SIZE = DATASET_SIZE_TYPE.small\n",
    "DISTRIBUTION_STRATEGY_TYPE = ''\n",
    "EMBEDDINGS_MODE = EMBEDDINGS_MODE_TYPE.vocabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:logging is ready\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.info('logging is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n",
      "INFO:root:training datset size: 366715\n",
      "INFO:root:training keras model\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "      1/Unknown - 11s 11s/step - loss: 0.6818 - accuracy: 0.7031WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.269923). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.269923). Check your callbacks.\n",
      "    803/Unknown - 47s 58ms/step - loss: 0.5215 - accuracy: 0.7507WARNING:tensorflow:This model was compiled with a Keras optimizer ([<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4274801ad0>, <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4274801250>]) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer ([<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4274801ad0>, <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4274801250>]) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "INFO:root:\n",
      "epoch train time: (hh:mm:ss.ms) 0:00:47.375055\n",
      "INFO:root:total train time: (hh:mm:ss.ms) 0:00:47.377857\n",
      "\n",
      "Epoch 00001: saving model to models/testing_keras/checkpoints/epochs:001-accuracy:0.751.hdf5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-32070169e907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_keras_sequential_wide_and_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/testing_keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5109eae47de>\u001b[0m in \u001b[0;36mtrain_keras_sequential_wide_and_deep\u001b[0;34m(strategy, model_dir)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_keras_sequential_wide_and_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m   \u001b[0mtrain_and_evaluate_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_keras_model_sequential_wide_and_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_keras_to_estimator_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5109eae47de>\u001b[0m in \u001b[0;36mtrain_and_evaluate_keras_model\u001b[0;34m(model, model_dir)\u001b[0m\n\u001b[1;32m    720\u001b[0m   \u001b[0mverbosity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN_LOCATION\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTRAIN_LOCATION_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training keras model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m   \u001b[0meval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done training keras model, evaluating model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5109eae47de>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'steps'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mepoch_milliseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} ms/step'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_milliseconds\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} microseconds/example'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch_milliseconds\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "result = train_keras_sequential_wide_and_deep(None, 'models/testing_keras')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:training for 5729 steps\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/testing3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/testing3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/testing3/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/testing3/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69287217, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69287217, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.6038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6525855, step = 100 (7.951 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6525855, step = 100 (7.951 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5878127, step = 200 (4.125 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5878127, step = 200 (4.125 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.8994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5041925, step = 300 (4.570 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5041925, step = 300 (4.570 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.6569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.544558, step = 400 (4.411 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.544558, step = 400 (4.411 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.1241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49990672, step = 500 (4.519 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49990672, step = 500 (4.519 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.6277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5973115, step = 600 (4.859 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5973115, step = 600 (4.859 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.8228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.8228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38138378, step = 700 (4.791 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38138378, step = 700 (4.791 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.9638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5078395, step = 800 (4.562 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5078395, step = 800 (4.562 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54564625, step = 900 (4.138 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54564625, step = 900 (4.138 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51205134, step = 1000 (3.842 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51205134, step = 1000 (3.842 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42094398, step = 1100 (3.651 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42094398, step = 1100 (3.651 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36360586, step = 1200 (3.613 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36360586, step = 1200 (3.613 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5397177, step = 1300 (4.555 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5397177, step = 1300 (4.555 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52376556, step = 1400 (3.729 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52376556, step = 1400 (3.729 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43249917, step = 1500 (3.850 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43249917, step = 1500 (3.850 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52172565, step = 1600 (3.985 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52172565, step = 1600 (3.985 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.0623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4974139, step = 1700 (4.533 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4974139, step = 1700 (4.533 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40841806, step = 1800 (3.937 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40841806, step = 1800 (3.937 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4150642, step = 1900 (4.125 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4150642, step = 1900 (4.125 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.0853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55074173, step = 2000 (4.184 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55074173, step = 2000 (4.184 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5719967, step = 2100 (4.547 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5719967, step = 2100 (4.547 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.2751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5884017, step = 2200 (3.778 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5884017, step = 2200 (3.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5357717, step = 2300 (4.397 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5357717, step = 2300 (4.397 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.3925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5844927, step = 2400 (3.787 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5844927, step = 2400 (3.787 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37730306, step = 2500 (3.651 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37730306, step = 2500 (3.651 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.5461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.5461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43150413, step = 2600 (3.397 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43150413, step = 2600 (3.397 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3548788, step = 2700 (3.539 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3548788, step = 2700 (3.539 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 32.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 32.7959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5632917, step = 2800 (3.048 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5632917, step = 2800 (3.048 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2865 into models/testing3/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2865 into models/testing3/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:19:31Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:19:31Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/testing3/model.ckpt-2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/testing3/model.ckpt-2865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.10706s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.10706s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:19:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:19:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2865: accuracy = 0.7639844, accuracy_baseline = 0.7459375, auc = 0.74003893, auc_precision_recall = 0.5000206, average_loss = 0.4952529, global_step = 2865, label/mean = 0.2540625, loss = 0.4952529, precision = 0.5686275, prediction/mean = 0.26315904, recall = 0.29428044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2865: accuracy = 0.7639844, accuracy_baseline = 0.7459375, auc = 0.74003893, auc_precision_recall = 0.5000206, average_loss = 0.4952529, global_step = 2865, label/mean = 0.2540625, loss = 0.4952529, precision = 0.5686275, prediction/mean = 0.26315904, recall = 0.29428044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2865: models/testing3/model.ckpt-2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2865: models/testing3/model.ckpt-2865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.42309645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.42309645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'accuracy': 0.7639844, 'accuracy_baseline': 0.7459375, 'auc': 0.74003893, 'auc_precision_recall': 0.5000206, 'average_loss': 0.4952529, 'label/mean': 0.2540625, 'loss': 0.4952529, 'precision': 0.5686275, 'prediction/mean': 0.26315904, 'recall': 0.29428044, 'global_step': 2865}, [])\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot set `iterations` to a new Variable after the Optimizer weights have been created",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-8829a9f6b888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_estimator_wide_and_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/testing3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-8829a9f6b888>\u001b[0m in \u001b[0;36mtrain_estimator_wide_and_deep\u001b[0;34m(model_dir, dnn_optimizer, linear_optimizer, dnn_hidden_units, dnn_dropout, batch_norm, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mtrain_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m           eval_spec=tf.estimator.EvalSpec(input_fn=lambda: get_dataset('test')))\n\u001b[0m\u001b[1;32m     48\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1194\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    594\u001b[0m           \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m           \u001b[0mlinear_sparse_combiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear_sparse_combiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m           loss_reduction=loss_reduction)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     super(DNNLinearCombinedClassifierV2, self).__init__(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_dnn_linear_combined_model_fn_v2\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdnn_logits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m       \u001b[0mdnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0mlinear_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizerV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_slot_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36miterations\u001b[0;34m(self, variable)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       raise RuntimeError(\"Cannot set `iterations` to a new Variable after \"\n\u001b[0m\u001b[1;32m    675\u001b[0m                          \"the Optimizer weights have been created\")\n\u001b[1;32m    676\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot set `iterations` to a new Variable after the Optimizer weights have been created"
     ]
    }
   ],
   "source": [
    "def get_max_steps():\n",
    "  dataset_size = FULL_TRAIN_DATASET_SIZE if DATASET_SIZE == DATASET_SIZE_TYPE.full else SMALL_TRAIN_DATASET_SIZE\n",
    "  return EPOCHS * dataset_size // BATCH_SIZE\n",
    "\n",
    "def train_estimator_wide_and_deep(model_dir, dnn_optimizer = tf.optimizers.SGD(learning_rate=0.05), linear_optimizer = tf.optimizers.SGD(learning_rate=0.05), dnn_hidden_units=[1024, 256, 128], dnn_dropout = None, batch_norm = False, batch_size = 128):\n",
    "    BATCH_SIZE = batch_size\n",
    "    \n",
    "    strategy = None\n",
    "    logging.info('training for {} steps'.format(get_max_steps()))\n",
    "    config = tf.estimator.RunConfig()\n",
    "\n",
    "    linear_feature_columns = create_linear_feature_columns()\n",
    "    corpus_dict = get_corpus_dict()\n",
    "    categorical_feature_columns_and_embeddings = create_categorical_embeddings_feature_columns(corpus_dict)\n",
    "    categorical_feature_columns = list(tf.feature_column.indicator_column(embedding.categorical_column) for embedding in categorical_feature_columns_and_embeddings)\n",
    "    embeddings = list(embedding for embedding in categorical_feature_columns_and_embeddings)\n",
    "\n",
    "    crossed_columns = list(tf.feature_column.indicator_column(tf.feature_column.crossed_column(\n",
    "        keys,\n",
    "        min(max(len(corpus_dict[keys[0]]), len(corpus_dict[keys[1]])), 100000))) for keys in KEY_CROSSES)\n",
    "\n",
    "    deep_model_feature_columns = embeddings + linear_feature_columns\n",
    "    wide_model_feature_columns = categorical_feature_columns + crossed_columns\n",
    "    estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "      dnn_optimizer=dnn_optimizer,\n",
    "      linear_optimizer=linear_optimizer,\n",
    "      linear_feature_columns=wide_model_feature_columns,\n",
    "      dnn_feature_columns=deep_model_feature_columns,\n",
    "      dnn_hidden_units=dnn_hidden_units,\n",
    "      model_dir=model_dir,\n",
    "      config=config,\n",
    "      dnn_dropout=dnn_dropout,\n",
    "      batch_norm=batch_norm,\n",
    "      n_classes=2)\n",
    "    logging.info('training wide and deep estimator model')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    #logging_hook = tf.estimator.LoggingTensorHook({\"train_loss\" : loss, \"accuracy\" : accuracy}, at_end=True)\n",
    "\n",
    "    for epoch in range(0, EPOCHS):\n",
    "      # Need to specify both max_steps and epochs. Each worker will go through epoch separately.\n",
    "      # see https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate?version=stable\n",
    "      result = tf.estimator.train_and_evaluate(\n",
    "          estimator,\n",
    "          train_spec=tf.estimator.TrainSpec(input_fn=lambda: get_dataset('train')),\n",
    "          eval_spec=tf.estimator.EvalSpec(input_fn=lambda: get_dataset('test')))\n",
    "      print(result)\n",
    "      results.append(result)\n",
    "    return results\n",
    "\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "    \n",
    "EPOCHS = 2    \n",
    "result = train_estimator_wide_and_deep('models/testing3')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3228863259472892401', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3228863259472892401', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3228863259472892401/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3228863259472892401/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7078527, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7078527, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.3564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37151596, step = 100 (8.095 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37151596, step = 100 (8.095 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36253798, step = 200 (4.140 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36253798, step = 200 (4.140 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27614915, step = 300 (4.045 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27614915, step = 300 (4.045 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5169817, step = 400 (4.019 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5169817, step = 400 (4.019 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53886414, step = 500 (3.847 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53886414, step = 500 (3.847 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.1343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45929322, step = 600 (3.689 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45929322, step = 600 (3.689 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7360033, step = 700 (3.676 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7360033, step = 700 (3.676 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5674416, step = 800 (4.215 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5674416, step = 800 (4.215 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53999496, step = 900 (5.023 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53999496, step = 900 (5.023 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.2293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6069339, step = 1000 (4.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6069339, step = 1000 (4.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5340136, step = 1100 (4.381 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5340136, step = 1100 (4.381 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.2668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.2668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3873448, step = 1200 (4.494 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3873448, step = 1200 (4.494 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.3971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.3971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62179273, step = 1300 (4.098 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62179273, step = 1300 (4.098 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5335641, step = 1400 (4.035 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5335641, step = 1400 (4.035 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51862717, step = 1500 (4.273 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51862717, step = 1500 (4.273 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47667035, step = 1600 (3.951 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47667035, step = 1600 (3.951 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62799835, step = 1700 (4.054 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62799835, step = 1700 (4.054 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6051233, step = 1800 (3.934 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6051233, step = 1800 (3.934 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.2804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39351803, step = 1900 (3.805 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39351803, step = 1900 (3.805 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62656033, step = 2000 (3.760 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62656033, step = 2000 (3.760 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.8147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.8147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36597937, step = 2100 (3.872 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36597937, step = 2100 (3.872 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5732049, step = 2200 (3.470 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5732049, step = 2200 (3.470 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4387139, step = 2300 (3.893 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4387139, step = 2300 (3.893 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.4514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47231025, step = 2400 (4.090 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47231025, step = 2400 (4.090 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41871107, step = 2500 (4.025 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41871107, step = 2500 (4.025 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57837915, step = 2600 (3.724 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57837915, step = 2600 (3.724 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.30714756, step = 2700 (4.208 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.30714756, step = 2700 (4.208 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3464111, step = 2800 (3.863 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3464111, step = 2800 (3.863 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3228863259472892401/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3228863259472892401/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T15:59:31Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T15:59:31Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3228863259472892401/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3228863259472892401/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.20361s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.20361s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-15:59:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-15:59:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.76484376, accuracy_baseline = 0.74359375, auc = 0.74176955, auc_precision_recall = 0.5051693, average_loss = 0.49611905, global_step = 2864, label/mean = 0.25640625, loss = 0.49611905, precision = 0.58607596, prediction/mean = 0.25514156, recall = 0.28214502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.76484376, accuracy_baseline = 0.74359375, auc = 0.74176955, auc_precision_recall = 0.5051693, average_loss = 0.49611905, global_step = 2864, label/mean = 0.25640625, loss = 0.49611905, precision = 0.58607596, prediction/mean = 0.25514156, recall = 0.28214502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3228863259472892401/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3228863259472892401/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6020064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6020064.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128 model_dir: models/3228863259472892401\n",
      "[({'accuracy': 0.76484376, 'accuracy_baseline': 0.74359375, 'auc': 0.74176955, 'auc_precision_recall': 0.5051693, 'average_loss': 0.49611905, 'label/mean': 0.25640625, 'loss': 0.49611905, 'precision': 0.58607596, 'prediction/mean': 0.25514156, 'recall': 0.28214502, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: False, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3705591861371476534', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3705591861371476534', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3705591861371476534/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3705591861371476534/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.68535167, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.68535167, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.500213, step = 100 (7.837 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.500213, step = 100 (7.837 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55000335, step = 200 (3.783 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55000335, step = 200 (3.783 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40574285, step = 300 (3.699 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40574285, step = 300 (3.699 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43866986, step = 400 (4.054 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43866986, step = 400 (4.054 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5247297, step = 500 (3.956 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5247297, step = 500 (3.956 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.4952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5615234, step = 600 (3.922 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5615234, step = 600 (3.922 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.72470474, step = 700 (4.130 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.72470474, step = 700 (4.130 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5462961, step = 800 (3.827 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5462961, step = 800 (3.827 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.29540083, step = 900 (3.983 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.29540083, step = 900 (3.983 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47628984, step = 1000 (3.764 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47628984, step = 1000 (3.764 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5714984, step = 1100 (3.792 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5714984, step = 1100 (3.792 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6015315, step = 1200 (3.895 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6015315, step = 1200 (3.895 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49304897, step = 1300 (3.944 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49304897, step = 1300 (3.944 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45580336, step = 1400 (3.969 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45580336, step = 1400 (3.969 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4624418, step = 1500 (3.882 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4624418, step = 1500 (3.882 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5057201, step = 1600 (4.262 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5057201, step = 1600 (4.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.63252133, step = 1700 (4.007 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.63252133, step = 1700 (4.007 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48027426, step = 1800 (3.831 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48027426, step = 1800 (3.831 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.5525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5226909, step = 1900 (4.434 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5226909, step = 1900 (4.434 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51471144, step = 2000 (4.004 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51471144, step = 2000 (4.004 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5298047, step = 2100 (3.740 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5298047, step = 2100 (3.740 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.2822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4075449, step = 2200 (4.477 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4075449, step = 2200 (4.477 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 18.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 18.5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4352205, step = 2300 (5.385 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4352205, step = 2300 (5.385 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.7658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.7658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37370104, step = 2400 (4.816 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37370104, step = 2400 (4.816 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.8454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5409181, step = 2500 (4.377 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5409181, step = 2500 (4.377 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41139242, step = 2600 (4.355 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41139242, step = 2600 (4.355 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.4468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1453178, step = 2700 (4.674 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.1453178, step = 2700 (4.674 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.19729736, step = 2800 (4.166 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.19729736, step = 2800 (4.166 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3705591861371476534/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3705591861371476534/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:02:15Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:02:15Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3705591861371476534/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3705591861371476534/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.98613s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.98613s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:02:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:02:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7671094, accuracy_baseline = 0.7480469, auc = 0.7417606, auc_precision_recall = 0.5044502, average_loss = 0.49366444, global_step = 2864, label/mean = 0.25195312, loss = 0.49366444, precision = 0.56243604, prediction/mean = 0.28073213, recall = 0.3407752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7671094, accuracy_baseline = 0.7480469, auc = 0.7417606, auc_precision_recall = 0.5044502, average_loss = 0.49366444, global_step = 2864, label/mean = 0.25195312, loss = 0.49366444, precision = 0.56243604, prediction/mean = 0.28073213, recall = 0.3407752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3705591861371476534/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3705591861371476534/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.5494442.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.5494442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: False, batch_size: 128 model_dir: models/3705591861371476534\n",
      "[({'accuracy': 0.7671094, 'accuracy_baseline': 0.7480469, 'auc': 0.7417606, 'auc_precision_recall': 0.5044502, 'average_loss': 0.49366444, 'label/mean': 0.25195312, 'loss': 0.49366444, 'precision': 0.56243604, 'prediction/mean': 0.28073213, 'recall': 0.3407752, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n",
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: True, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/2697968239304707355', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/2697968239304707355', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/2697968239304707355/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/2697968239304707355/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6867555, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6867555, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42677036, step = 100 (7.452 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42677036, step = 100 (7.452 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.0495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69654393, step = 200 (4.338 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69654393, step = 200 (4.338 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5354426, step = 300 (3.941 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5354426, step = 300 (3.941 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58633083, step = 400 (4.011 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58633083, step = 400 (4.011 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.664951, step = 500 (4.063 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.664951, step = 500 (4.063 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.3589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21151003, step = 600 (3.781 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.21151003, step = 600 (3.781 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.5622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36358145, step = 700 (4.074 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36358145, step = 700 (4.074 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53447855, step = 800 (4.386 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53447855, step = 800 (4.386 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7115001, step = 900 (3.983 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7115001, step = 900 (3.983 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56495476, step = 1000 (4.174 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56495476, step = 1000 (4.174 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36961558, step = 1100 (3.653 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36961558, step = 1100 (3.653 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60967416, step = 1200 (4.053 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60967416, step = 1200 (4.053 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.9546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4568622, step = 1300 (3.577 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4568622, step = 1300 (3.577 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5595485, step = 1400 (4.027 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5595485, step = 1400 (4.027 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61054564, step = 1500 (3.958 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61054564, step = 1500 (3.958 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6384659, step = 1600 (3.697 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6384659, step = 1600 (3.697 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57727754, step = 1700 (3.826 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57727754, step = 1700 (3.826 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54749876, step = 1800 (3.843 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54749876, step = 1800 (3.843 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5452596, step = 1900 (4.148 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5452596, step = 1900 (4.148 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.5282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.5282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39670527, step = 2000 (4.455 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39670527, step = 2000 (4.455 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5876018, step = 2100 (3.945 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5876018, step = 2100 (3.945 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.46734956, step = 2200 (4.066 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.46734956, step = 2200 (4.066 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6701797, step = 2300 (3.969 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6701797, step = 2300 (3.969 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58544254, step = 2400 (3.691 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58544254, step = 2400 (3.691 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.1175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3362131, step = 2500 (3.557 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3362131, step = 2500 (3.557 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3554262, step = 2600 (3.425 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3554262, step = 2600 (3.425 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.7804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45714772, step = 2700 (3.594 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45714772, step = 2700 (3.594 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.8721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.8721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35928738, step = 2800 (3.585 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35928738, step = 2800 (3.585 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/2697968239304707355/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/2697968239304707355/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:04:52Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:04:52Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/2697968239304707355/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/2697968239304707355/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 9.53717s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 9.53717s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:05:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:05:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7669531, accuracy_baseline = 0.7433594, auc = 0.74190176, auc_precision_recall = 0.50693387, average_loss = 0.495724, global_step = 2864, label/mean = 0.2566406, loss = 0.495724, precision = 0.6107038, prediction/mean = 0.24631134, recall = 0.25357687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7669531, accuracy_baseline = 0.7433594, auc = 0.74190176, auc_precision_recall = 0.50693387, average_loss = 0.495724, global_step = 2864, label/mean = 0.2566406, loss = 0.495724, precision = 0.6107038, prediction/mean = 0.24631134, recall = 0.25357687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/2697968239304707355/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/2697968239304707355/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6108568.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.6108568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: True, batch_size: 128 model_dir: models/2697968239304707355\n",
      "[({'accuracy': 0.7669531, 'accuracy_baseline': 0.7433594, 'auc': 0.74190176, 'auc_precision_recall': 0.50693387, 'average_loss': 0.495724, 'label/mean': 0.2566406, 'loss': 0.495724, 'precision': 0.6107038, 'prediction/mean': 0.24631134, 'recall': 0.25357687, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n",
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: True, batch_size: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3722580483906617289', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3722580483906617289', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3722580483906617289/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3722580483906617289/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6789569, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6789569, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.6603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44920677, step = 100 (7.900 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44920677, step = 100 (7.900 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61276305, step = 200 (4.350 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61276305, step = 200 (4.350 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5281816, step = 300 (3.741 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5281816, step = 300 (3.741 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3816867, step = 400 (3.728 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3816867, step = 400 (3.728 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55601203, step = 500 (3.900 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.55601203, step = 500 (3.900 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49159586, step = 600 (3.942 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49159586, step = 600 (3.942 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56850594, step = 700 (3.929 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56850594, step = 700 (3.929 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6173773, step = 800 (3.957 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6173773, step = 800 (3.957 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.7002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5724399, step = 900 (4.404 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5724399, step = 900 (4.404 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.1993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6614933, step = 1000 (3.814 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6614933, step = 1000 (3.814 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5446671, step = 1100 (3.960 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5446671, step = 1100 (3.960 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58614063, step = 1200 (3.955 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58614063, step = 1200 (3.955 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52296174, step = 1300 (3.932 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52296174, step = 1300 (3.932 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.6181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5705257, step = 1400 (3.491 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5705257, step = 1400 (3.491 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37590337, step = 1500 (3.845 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37590337, step = 1500 (3.845 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48074687, step = 1600 (3.622 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48074687, step = 1600 (3.622 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5318576, step = 1700 (3.913 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5318576, step = 1700 (3.913 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49948314, step = 1800 (3.855 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49948314, step = 1800 (3.855 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54956853, step = 1900 (4.230 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.54956853, step = 1900 (4.230 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38267136, step = 2000 (3.638 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.38267136, step = 2000 (3.638 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5957259, step = 2100 (3.994 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5957259, step = 2100 (3.994 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52175474, step = 2200 (4.410 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52175474, step = 2200 (4.410 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.6824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5562745, step = 2300 (4.052 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5562745, step = 2300 (4.052 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5027004, step = 2400 (3.796 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5027004, step = 2400 (3.796 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45021898, step = 2500 (3.722 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45021898, step = 2500 (3.722 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4321621, step = 2600 (4.211 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4321621, step = 2600 (4.211 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.532015, step = 2700 (4.225 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.532015, step = 2700 (4.225 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.1338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4292835, step = 2800 (4.322 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4292835, step = 2800 (4.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3722580483906617289/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3722580483906617289/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:07:30Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:07:30Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3722580483906617289/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3722580483906617289/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.53313s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.53313s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:07:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:07:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.76484376, accuracy_baseline = 0.7441406, auc = 0.73933375, auc_precision_recall = 0.50276107, average_loss = 0.49646688, global_step = 2864, label/mean = 0.25585938, loss = 0.49646688, precision = 0.5891056, prediction/mean = 0.25621337, recall = 0.2674809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.76484376, accuracy_baseline = 0.7441406, auc = 0.73933375, auc_precision_recall = 0.50276107, average_loss = 0.49646688, global_step = 2864, label/mean = 0.25585938, loss = 0.49646688, precision = 0.5891056, prediction/mean = 0.25621337, recall = 0.2674809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3722580483906617289/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3722580483906617289/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.61312336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.61312336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:Adagrad 0.001, linear_optimizer:Ftrl 0.001, dnn_hidden_units: [1024, 256, 128], dnn_dropout:0.01, batch_norm: True, batch_size: 256 model_dir: models/3722580483906617289\n",
      "[({'accuracy': 0.76484376, 'accuracy_baseline': 0.7441406, 'auc': 0.73933375, 'auc_precision_recall': 0.50276107, 'average_loss': 0.49646688, 'label/mean': 0.25585938, 'loss': 0.49646688, 'precision': 0.5891056, 'prediction/mean': 0.25621337, 'recall': 0.2674809, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n",
      "dnn_optimizer:SGD 0.100, linear_optimizer:SGD 0.100, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/6409087268702871103', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/6409087268702871103', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/6409087268702871103/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/6409087268702871103/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7051277, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7051277, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35135388, step = 100 (8.266 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35135388, step = 100 (8.266 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.4015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35915732, step = 200 (4.465 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35915732, step = 200 (4.465 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42551732, step = 300 (3.920 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42551732, step = 300 (3.920 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.3831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48276466, step = 400 (3.664 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48276466, step = 400 (3.664 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5565097, step = 500 (3.966 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5565097, step = 500 (3.966 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.7757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47741216, step = 600 (4.035 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.47741216, step = 600 (4.035 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6366002, step = 700 (3.950 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6366002, step = 700 (3.950 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59738255, step = 800 (4.021 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59738255, step = 800 (4.021 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4278046, step = 900 (4.181 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4278046, step = 900 (4.181 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5834959, step = 1000 (3.457 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5834959, step = 1000 (3.457 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.5149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4238624, step = 1100 (3.919 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4238624, step = 1100 (3.919 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40849373, step = 1200 (4.172 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.40849373, step = 1200 (4.172 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50359, step = 1300 (3.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50359, step = 1300 (3.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62970084, step = 1400 (3.748 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62970084, step = 1400 (3.748 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5451653, step = 1500 (3.780 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5451653, step = 1500 (3.780 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4941922, step = 1600 (3.685 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4941922, step = 1600 (3.685 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4296654, step = 1700 (3.646 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4296654, step = 1700 (3.646 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56364596, step = 1800 (3.417 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56364596, step = 1800 (3.417 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.5827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62208605, step = 1900 (4.634 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.62208605, step = 1900 (4.634 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50166136, step = 2000 (4.689 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50166136, step = 2000 (4.689 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41152388, step = 2100 (3.447 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41152388, step = 2100 (3.447 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5512605, step = 2200 (3.744 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5512605, step = 2200 (3.744 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.9887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5075137, step = 2300 (3.848 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5075137, step = 2300 (3.848 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58468926, step = 2400 (3.739 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58468926, step = 2400 (3.739 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32463968, step = 2500 (3.880 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.32463968, step = 2500 (3.880 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2596792, step = 2600 (3.957 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.2596792, step = 2600 (3.957 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.34053397, step = 2700 (3.882 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.34053397, step = 2700 (3.882 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4427234, step = 2800 (3.731 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4427234, step = 2800 (3.731 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/6409087268702871103/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/6409087268702871103/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:10:06Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:10:06Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/6409087268702871103/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/6409087268702871103/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.67187s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.67187s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:10:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:10:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7727344, accuracy_baseline = 0.75039065, auc = 0.73881936, auc_precision_recall = 0.4975507, average_loss = 0.49103773, global_step = 2864, label/mean = 0.24960938, loss = 0.49103773, precision = 0.6131329, prediction/mean = 0.24114205, recall = 0.24256651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7727344, accuracy_baseline = 0.75039065, auc = 0.73881936, auc_precision_recall = 0.4975507, average_loss = 0.49103773, global_step = 2864, label/mean = 0.24960938, loss = 0.49103773, precision = 0.6131329, prediction/mean = 0.24114205, recall = 0.24256651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/6409087268702871103/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/6409087268702871103/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.46797478.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.46797478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:SGD 0.100, linear_optimizer:SGD 0.100, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128 model_dir: models/6409087268702871103\n",
      "[({'accuracy': 0.7727344, 'accuracy_baseline': 0.75039065, 'auc': 0.73881936, 'auc_precision_recall': 0.4975507, 'average_loss': 0.49103773, 'label/mean': 0.24960938, 'loss': 0.49103773, 'precision': 0.6131329, 'prediction/mean': 0.24114205, 'recall': 0.24256651, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n",
      "dnn_optimizer:SGD 0.050, linear_optimizer:SGD 0.050, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/5273354343659414609', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/5273354343659414609', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/5273354343659414609/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/5273354343659414609/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69391394, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.69391394, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 12.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5835682, step = 100 (8.093 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5835682, step = 100 (8.093 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7160115, step = 200 (3.436 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7160115, step = 200 (3.436 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5602122, step = 300 (3.768 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5602122, step = 300 (3.768 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42794043, step = 400 (3.901 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.42794043, step = 400 (3.901 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.586583, step = 500 (4.009 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.586583, step = 500 (4.009 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.655921, step = 600 (3.906 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.655921, step = 600 (3.906 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.82394856, step = 700 (4.140 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.82394856, step = 700 (4.140 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48737204, step = 800 (4.114 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48737204, step = 800 (4.114 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.6475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49420542, step = 900 (3.387 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49420542, step = 900 (3.387 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53493667, step = 1000 (3.889 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.53493667, step = 1000 (3.889 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5096507, step = 1100 (3.985 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5096507, step = 1100 (3.985 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59266686, step = 1200 (3.410 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59266686, step = 1200 (3.410 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35700417, step = 1300 (3.553 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35700417, step = 1300 (3.553 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5911701, step = 1400 (3.891 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5911701, step = 1400 (3.891 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.633037, step = 1500 (4.121 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.633037, step = 1500 (4.121 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.3869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58110225, step = 1600 (3.523 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.58110225, step = 1600 (3.523 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57072234, step = 1700 (3.702 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57072234, step = 1700 (3.702 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.3345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.3345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.470053, step = 1800 (3.533 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.470053, step = 1800 (3.533 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59197956, step = 1900 (3.692 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59197956, step = 1900 (3.692 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.2826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50897276, step = 2000 (3.539 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.50897276, step = 2000 (3.539 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36119992, step = 2100 (3.721 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36119992, step = 2100 (3.721 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60733044, step = 2200 (3.832 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60733044, step = 2200 (3.832 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51495624, step = 2300 (3.749 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51495624, step = 2300 (3.749 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37475938, step = 2400 (3.408 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.37475938, step = 2400 (3.408 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36812305, step = 2500 (3.653 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36812305, step = 2500 (3.653 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27056795, step = 2600 (3.981 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.27056795, step = 2600 (3.981 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4298466, step = 2700 (3.422 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4298466, step = 2700 (3.422 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5916159, step = 2800 (3.231 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5916159, step = 2800 (3.231 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/5273354343659414609/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/5273354343659414609/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:12:41Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:12:41Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/5273354343659414609/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/5273354343659414609/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 9.78260s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 9.78260s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:12:51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:12:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.77546877, accuracy_baseline = 0.75875, auc = 0.7414632, auc_precision_recall = 0.48708025, average_loss = 0.48189297, global_step = 2864, label/mean = 0.24125, loss = 0.48189297, precision = 0.5772006, prediction/mean = 0.24642734, recall = 0.25906736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.77546877, accuracy_baseline = 0.75875, auc = 0.7414632, auc_precision_recall = 0.48708025, average_loss = 0.48189297, global_step = 2864, label/mean = 0.24125, loss = 0.48189297, precision = 0.5772006, prediction/mean = 0.24642734, recall = 0.25906736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/5273354343659414609/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/5273354343659414609/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.5380272.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.5380272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:root:training for 2864 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:SGD 0.050, linear_optimizer:SGD 0.050, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128 model_dir: models/5273354343659414609\n",
      "[({'accuracy': 0.77546877, 'accuracy_baseline': 0.75875, 'auc': 0.7414632, 'auc_precision_recall': 0.48708025, 'average_loss': 0.48189297, 'label/mean': 0.24125, 'loss': 0.48189297, 'precision': 0.5772006, 'prediction/mean': 0.24642734, 'recall': 0.25906736, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n",
      "dnn_optimizer:SGD 0.010, linear_optimizer:SGD 0.010, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "INFO:root:categorical column with vocabular cat1 corpus_size 98\n",
      "INFO:root:categorical column with vocabular cat2 corpus_size 364\n",
      "INFO:root:categorical column with vocabular cat3 corpus_size 624\n",
      "INFO:root:categorical column with vocabular cat4 corpus_size 830\n",
      "INFO:root:categorical column with vocabular cat5 corpus_size 38\n",
      "INFO:root:categorical column with vocabular cat6 corpus_size 8\n",
      "INFO:root:categorical column cat6 corpus_size 8 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat7 corpus_size 1764\n",
      "INFO:root:categorical column with vocabular cat8 corpus_size 60\n",
      "INFO:root:categorical column with vocabular cat9 corpus_size 3\n",
      "INFO:root:categorical column cat9 corpus_size 3 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat10 corpus_size 1267\n",
      "INFO:root:categorical column with vocabular cat11 corpus_size 1529\n",
      "INFO:root:categorical column with vocabular cat12 corpus_size 646\n",
      "INFO:root:categorical column with vocabular cat13 corpus_size 1356\n",
      "INFO:root:categorical column with vocabular cat14 corpus_size 23\n",
      "INFO:root:categorical column with vocabular cat15 corpus_size 1254\n",
      "INFO:root:categorical column with vocabular cat16 corpus_size 727\n",
      "INFO:root:categorical column with vocabular cat17 corpus_size 9\n",
      "INFO:root:categorical column cat17 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat18 corpus_size 836\n",
      "INFO:root:categorical column with vocabular cat19 corpus_size 284\n",
      "INFO:root:categorical column with vocabular cat20 corpus_size 4\n",
      "INFO:root:categorical column cat20 corpus_size 4 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat21 corpus_size 667\n",
      "INFO:root:categorical column with vocabular cat22 corpus_size 9\n",
      "INFO:root:categorical column cat22 corpus_size 9 - creating indicator column\n",
      "INFO:root:categorical column with vocabular cat23 corpus_size 12\n",
      "INFO:root:categorical column with vocabular cat24 corpus_size 822\n",
      "INFO:root:categorical column with vocabular cat25 corpus_size 37\n",
      "INFO:root:categorical column with vocabular cat26 corpus_size 601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3821055518037430863', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/3821055518037430863', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:root:training wide and deep estimator model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3821055518037430863/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into models/3821055518037430863/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7853893, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.7853893, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.6526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.6526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51653564, step = 100 (7.327 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51653564, step = 100 (7.327 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.7015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3575085, step = 200 (4.226 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3575085, step = 200 (4.226 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5069931, step = 300 (3.697 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5069931, step = 300 (3.697 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.0939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.592058, step = 400 (3.691 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.592058, step = 400 (3.691 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6454071, step = 500 (4.317 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6454071, step = 500 (4.317 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.3896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43633416, step = 600 (3.936 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43633416, step = 600 (3.936 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.2855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5330802, step = 700 (3.955 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5330802, step = 700 (3.955 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44787422, step = 800 (3.738 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.44787422, step = 800 (3.738 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.5075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.5075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48396605, step = 900 (4.080 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.48396605, step = 900 (4.080 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.5988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28066766, step = 1000 (3.763 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28066766, step = 1000 (3.763 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.5389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52669126, step = 1100 (3.501 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.52669126, step = 1100 (3.501 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5795294, step = 1200 (3.721 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5795294, step = 1200 (3.721 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.1942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60280055, step = 1300 (3.677 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.60280055, step = 1300 (3.677 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5944369, step = 1400 (3.412 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5944369, step = 1400 (3.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43362397, step = 1500 (4.224 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.43362397, step = 1500 (4.224 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5862763, step = 1600 (4.129 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5862763, step = 1600 (4.129 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81638956, step = 1700 (3.741 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81638956, step = 1700 (3.741 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 27.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51866347, step = 1800 (3.592 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.51866347, step = 1800 (3.592 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.6783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5714768, step = 1900 (3.748 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5714768, step = 1900 (3.748 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 26.4746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45123112, step = 2000 (3.778 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.45123112, step = 2000 (3.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.4509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49945456, step = 2100 (3.284 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49945456, step = 2100 (3.284 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36648065, step = 2200 (3.494 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.36648065, step = 2200 (3.494 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6294267, step = 2300 (3.876 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6294267, step = 2300 (3.876 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5654563, step = 2400 (3.472 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5654563, step = 2400 (3.472 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.5303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35694674, step = 2500 (3.372 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.35694674, step = 2500 (3.372 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.4425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17420678, step = 2600 (4.262 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.17420678, step = 2600 (4.262 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 28.6456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39502287, step = 2700 (3.492 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.39502287, step = 2700 (3.492 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 30.996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59612083, step = 2800 (3.230 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.59612083, step = 2800 (3.230 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3821055518037430863/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2864 into models/3821055518037430863/model.ckpt.\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function transform_row at 0x7f30a48345f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:15:13Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-02-21T16:15:13Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3821055518037430863/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/3821055518037430863/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.00359s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 10.00359s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:15:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-02-21-16:15:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7646094, accuracy_baseline = 0.7435156, auc = 0.74703085, auc_precision_recall = 0.510986, average_loss = 0.49254748, global_step = 2864, label/mean = 0.2564844, loss = 0.49254748, precision = 0.5790398, prediction/mean = 0.26196653, recall = 0.30124885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2864: accuracy = 0.7646094, accuracy_baseline = 0.7435156, auc = 0.74703085, auc_precision_recall = 0.510986, average_loss = 0.49254748, global_step = 2864, label/mean = 0.2564844, loss = 0.49254748, precision = 0.5790398, prediction/mean = 0.26196653, recall = 0.30124885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3821055518037430863/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2864: models/3821055518037430863/model.ckpt-2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.46470475.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.46470475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_optimizer:SGD 0.010, linear_optimizer:SGD 0.010, dnn_hidden_units: [1024, 256, 128], dnn_dropout:None, batch_norm: False, batch_size: 128 model_dir: models/3821055518037430863\n",
      "[({'accuracy': 0.7646094, 'accuracy_baseline': 0.7435156, 'auc': 0.74703085, 'auc_precision_recall': 0.510986, 'average_loss': 0.49254748, 'label/mean': 0.2564844, 'loss': 0.49254748, 'precision': 0.5790398, 'prediction/mean': 0.26196653, 'recall': 0.30124885, 'global_step': 2864}, []), (None, None), (None, None), (None, None), (None, None)]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "TRAIN_LOCATION = TRAIN_LOCATION_TYPE.local\n",
    "DATASET_SOURCE = DATASET_SOURCE_TYPE.bq\n",
    "DATASET_SIZE = DATASET_SIZE_TYPE.small\n",
    "DISTRIBUTION_STRATEGY_TYPE = ''\n",
    "EMBEDDINGS_MODE = EMBEDDINGS_MODE_TYPE.vocabular\n",
    "\n",
    "params = [\n",
    "    {'dnn_optimizer': tf.keras.optimizers.Adagrad(), 'linear_optimizer': tf.keras.optimizers.Ftrl(), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':None, 'batch_norm': False, 'batch_size': 128},\n",
    "    {'dnn_optimizer': tf.keras.optimizers.Adagrad(), 'linear_optimizer': tf.keras.optimizers.Ftrl(), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':0.01, 'batch_norm': False, 'batch_size': 128},\n",
    "    {'dnn_optimizer': tf.keras.optimizers.Adagrad(), 'linear_optimizer': tf.keras.optimizers.Ftrl(), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':0.01, 'batch_norm': True, 'batch_size': 128},\n",
    "    {'dnn_optimizer': tf.keras.optimizers.Adagrad(), 'linear_optimizer': tf.keras.optimizers.Ftrl(), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':0.01, 'batch_norm': True, 'batch_size': 256},\n",
    "    {'dnn_optimizer': tf.optimizers.SGD(learning_rate=0.1), 'linear_optimizer': tf.optimizers.SGD(learning_rate=0.1), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':None, 'batch_norm': False, 'batch_size': 128},\n",
    "    {'dnn_optimizer': tf.optimizers.SGD(learning_rate=0.05), 'linear_optimizer': tf.optimizers.SGD(learning_rate=0.05), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':None, 'batch_norm': False, 'batch_size': 128},\n",
    "    {'dnn_optimizer': tf.optimizers.SGD(learning_rate=0.01), 'linear_optimizer': tf.optimizers.SGD(learning_rate=0.01), 'dnn_hidden_units':[1024, 256, 128], 'dnn_dropout':None, 'batch_norm': False, 'batch_size': 128}\n",
    "]\n",
    "\n",
    "for params_dict in params:\n",
    "    dnn_optimizer = params_dict['dnn_optimizer']\n",
    "    linear_optimizer = params_dict['linear_optimizer']\n",
    "    dnn_hidden_units = params_dict['dnn_hidden_units']\n",
    "    dnn_dropout = params_dict['dnn_dropout']\n",
    "    batch_norm = params_dict['batch_norm']\n",
    "    batch_size = params_dict['batch_size']\n",
    "    \n",
    "    args_string = 'dnn_optimizer:{dnn_optimizer} {dnn_optimizer_lr:.3f}, linear_optimizer:{linear_optimizer} {linear_optimizer_lr:.3f}, dnn_hidden_units: {dnn_hidden_units}, dnn_dropout:{dnn_dropout}, batch_norm: {batch_norm}, batch_size: {batch_size}'.format(\n",
    "      dnn_optimizer=type(dnn_optimizer).__name__, dnn_optimizer_lr=dnn_optimizer.learning_rate.numpy(),\n",
    "      linear_optimizer=type(linear_optimizer).__name__, linear_optimizer_lr=linear_optimizer.learning_rate.numpy(),\n",
    "      dnn_hidden_units=dnn_hidden_units,\n",
    "      dnn_dropout = dnn_dropout, \n",
    "      batch_norm = batch_norm,\n",
    "      batch_size = batch_size)\n",
    "    print(args_string)\n",
    "    args_string_hash = abs(hash(args_string))\n",
    "    model_dir = 'models/' + str(args_string_hash)\n",
    "    args_string = args_string + ' model_dir: ' + model_dir\n",
    "    \n",
    "    results = train_estimator_wide_and_deep(model_dir, dnn_optimizer = dnn_optimizer, linear_optimizer = linear_optimizer, dnn_hidden_units=dnn_hidden_units, dnn_dropout = dnn_dropout, batch_norm = batch_norm, batch_size = batch_size)\n",
    "    \n",
    "    print(args_string)\n",
    "    print(results)\n",
    "    \n",
    "    f = open(\"train_estimator_wide_and_deep_experiments.txt\", \"a\")\n",
    "    \n",
    "    f.write(args_string)\n",
    "    f.write('\\n')\n",
    "    f.write(str(results))\n",
    "    f.write('\\n\\n')\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add_variable_with_custom_getter', '_assert_valid_dtypes', '_call_if_callable', '_checkpoint_dependencies', '_compute_gradients', '_create_hypers', '_create_or_restore_slot_variable', '_create_slots', '_decayed_lr', '_deferred_dependencies', '_dense_apply_args', '_distributed_apply', '_fallback_apply_state', '_gather_saveables_for_checkpoint', '_get_hyper', '_handle_deferred_dependencies', '_init_set_name', '_keras_api_names', '_keras_api_names_v1', '_list_extra_dependencies_for_serialization', '_list_functions_for_serialization', '_lookup_dependency', '_maybe_initialize_trackable', '_name_based_attribute_restore', '_name_based_restores', '_no_dependency', '_object_identifier', '_preload_simple_restoration', '_prepare', '_prepare_local', '_resource_apply_dense', '_resource_apply_sparse', '_resource_apply_sparse_duplicate_indices', '_resource_scatter_add', '_resource_scatter_update', '_restore_from_checkpoint_position', '_restore_slot_variable', '_serialize_hyperparameter', '_set_hyper', '_setattr_tracking', '_single_restoration_from_checkpoint_position', '_sparse_apply_args', '_track_trackable', '_tracking_metadata', '_unconditional_checkpoint_dependencies', '_unconditional_dependency_names', '_update_uid', '_valid_dtypes', 'add_slot', 'add_weight', 'apply_gradients', 'from_config', 'get_config', 'get_gradients', 'get_slot', 'get_slot_names', 'get_updates', 'get_weights', 'iterations', 'minimize', 'set_weights', 'variables', 'weights']\n",
      "SGD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 6]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.optimizers.SGD(learning_rate=0.05).learning_rate.numpy()\n",
    "print(dir(type(tf.optimizers.SGD(learning_rate=0.05))))\n",
    "print(tf.optimizers.SGD(learning_rate=0.05).__class__.__name__)\n",
    "\n",
    "\n",
    "l = [3]\n",
    "l.append(6)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLossesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CSV_SCHEMA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8092d88397da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformed_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_raw_kaggle_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8092d88397da>\u001b[0m in \u001b[0;36mread_raw_kaggle_gcs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_raw_kaggle_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgcs_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0000'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrecord_defaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'label'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCSV_SCHEMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCsvDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcs_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_defaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_delim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CSV_SCHEMA' is not defined"
     ]
    }
   ],
   "source": [
    "def read_raw_kaggle_gcs():\n",
    "    gcs_filename = 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0000'\n",
    "    record_defaults = list(tf.int32 if field.name == 'label' else tf.constant(0, dtype=tf.int32) if field.name.startswith('int') else tf.constant('', dtype=tf.string) for field in CSV_SCHEMA)\n",
    "    dataset = tf.data.experimental.CsvDataset(gcs_filename, record_defaults, field_delim='\\t', header=False)\n",
    "    \n",
    "    def transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus):\n",
    "        row_dict = dict(zip(list(field.name for field in CSV_SCHEMA), list(row_tuple)))\n",
    "        return transform_row(row_dict, mean_dict, std_dict, corpus)    \n",
    "\n",
    "    corpus = get_corpus()\n",
    "    (mean_dict, std_dict) = get_mean_and_std_dicts()\n",
    "    transofrom_row_gcs_function = lambda *row_tuple: transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus)\n",
    "\n",
    "    transformed_ds = dataset\\\n",
    "      .batch(BATCH_SIZE) \\\n",
    "      .map (transofrom_row_gcs_function) \\\n",
    "      .shuffle(50) \\\n",
    "      .prefetch(50)\n",
    "    return transformed_ds\n",
    "\n",
    "for row in read_raw_kaggle_gcs().take(1):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_names(file_pattern):\n",
    "    if isinstance(file_pattern, list):\n",
    "        if not file_pattern:\n",
    "            raise ValueError(\"File pattern is empty.\")\n",
    "        file_names = []\n",
    "        for entry in file_pattern:\n",
    "            file_names.extend(gfile.Glob(entry))\n",
    "    else:\n",
    "        file_names = list(gfile.Glob(file_pattern))\n",
    "    return file_names\n",
    "        \n",
    "file_names = _get_file_names(\"gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0*\")\n",
    "\n",
    "#file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0001',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0002',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0003',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0004',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0005',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0006',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0007',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0008',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0010',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0011',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0012',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0013',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0014',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0015',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0016',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0017',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0019',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0020',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0021',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0022',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0023',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0024',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0025',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0026',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0028',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0029',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0030',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0031',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0032',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0033',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0034',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0035',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0037',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0038',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0039',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0040',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0041',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0042',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0043',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0044',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0046',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0047',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0048',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0049',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0050',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0051',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0052',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0053',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0055',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0056',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0057',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0058',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0059',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0060',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0061',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0062',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0064',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0065',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0066',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0067',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0068',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0069',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0070',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0071',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0073',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0074',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0075',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0076',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0077',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0078',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0079',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0080',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0082',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0083',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0084',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0085',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0086',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0087',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0088',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0089',\n",
       " 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0091']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def _get_file_suffix(file_name):\n",
    "    return int(re.search('gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_(\\d+)', file_name).group(1))\n",
    "\n",
    "def _get_file_names_with_validation_split(is_training, validation_split):\n",
    "    file_names = _get_file_names(\"gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train_0*\")\n",
    "    modulo = int(len(file_names) * validation_split)\n",
    "    return list(file_name for file_name in file_names if is_training ^ (_get_file_suffix(file_name) % modulo == 0))\n",
    "\n",
    "_get_file_names_with_validation_split(True, 0.1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.8.3)\n",
      "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: saving model to gs://alekseyv-scalableai-dev-criteo-model-bucket/models_jupyter/model_full_adam_raw_gcs_1/checkpoints/epochs:003-accuracy:0.744.hdf5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8e7de66943dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     callbacks=callbacks)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;31m#model.fit(training_ds, epochs=EPOCHS, verbose=verbosity, callbacks=callbacks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done training keras model, evaluating model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def read_raw_kaggle_gcs_one_file():\n",
    "    gcs_filename = 'gs://alekseyv-scalableai-dev-public-bucket/criteo_kaggle_decompressed/train.txt'\n",
    "    record_defaults = list(tf.int32 if field.name == 'label' else tf.constant(0, dtype=tf.int32) if field.name.startswith('int') else tf.constant('', dtype=tf.string) for field in CSV_SCHEMA)\n",
    "    dataset = tf.data.experimental.CsvDataset(gcs_filename, record_defaults, field_delim='\\t', header=False)\n",
    "    \n",
    "    def transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus):\n",
    "        row_dict = dict(zip(list(field.name for field in CSV_SCHEMA), list(row_tuple)))\n",
    "        return transform_row(row_dict, mean_dict, std_dict, corpus)        \n",
    "\n",
    "    corpus = get_corpus()\n",
    "    (mean_dict, std_dict) = get_mean_and_std_dicts()\n",
    "    transofrom_row_gcs_function = lambda *row_tuple: transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus)\n",
    "\n",
    "    transformed_ds = dataset\\\n",
    "      .batch(BATCH_SIZE) \\\n",
    "      .shuffle(50) \\\n",
    "      .map (transofrom_row_gcs_function) \\\n",
    "      .prefetch(50)\n",
    "    return transformed_ds\n",
    "\n",
    "\n",
    "def read_raw_kaggle_gcs(is_training):\n",
    "    file_names = _get_file_names_with_validation_split(is_training, 0.2)\n",
    "    num_parallel_calls = max(10, len(file_names))\n",
    "    file_names_ds = dataset_ops.Dataset.from_tensor_slices(file_names).shuffle(buffer_size=20)\n",
    "    record_defaults = list(tf.int32 if field.name == 'label' else tf.constant(0, dtype=tf.int32) if field.name.startswith('int') else tf.constant('', dtype=tf.string) for field in CSV_SCHEMA)\n",
    "    dataset = file_names_ds.interleave(\n",
    "          lambda file_name: tf.data.experimental.CsvDataset(file_name, record_defaults, field_delim='\\t', header=False),\n",
    "          cycle_length=num_parallel_calls,\n",
    "          num_parallel_calls=num_parallel_calls)\n",
    "    \n",
    "    def transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus):\n",
    "        row_dict = dict(zip(list(field.name for field in CSV_SCHEMA), list(row_tuple)))\n",
    "        return transform_row(row_dict, mean_dict, std_dict, corpus)       \n",
    "\n",
    "    corpus = get_corpus()\n",
    "    (mean_dict, std_dict) = get_mean_and_std_dicts()\n",
    "    transofrom_row_gcs_function = lambda *row_tuple: transofrom_row_gcs(row_tuple, mean_dict, std_dict, corpus)\n",
    "\n",
    "    transformed_ds = dataset\\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .shuffle(50) \\\n",
    "    .map (transofrom_row_gcs_function, num_parallel_calls=num_parallel_calls) \\\n",
    "    .prefetch(50)\n",
    "    return transformed_ds\n",
    "\n",
    "\n",
    "DATASET_SOURCE = DATASET_SOURCE_TYPE.gcs\n",
    "DATASET_SIZE = DATASET_SIZE_TYPE.full\n",
    "EPOCHS = 5\n",
    "dataset_size = FULL_TRAIN_DATASET_SIZE\n",
    "logging.info('training datset size: {}'.format(dataset_size))\n",
    "\n",
    "model_dir = 'gs://alekseyv-scalableai-dev-criteo-model-bucket/models_jupyter/model_full_adam_raw_gcs_1'\n",
    "feature_columns = create_feature_columns()\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns, name=\"feature_layer\")\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "#kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2',values=[1e-1, 1e-2, 1e-3]))\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "  feature_layer,\n",
    "  Dropout(0.1),\n",
    "  Dense(600, activation=tf.nn.relu),\n",
    "  Dense(600, activation=tf.nn.relu),\n",
    "  Dense(600, activation=tf.nn.relu),\n",
    "  Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "logging.info('compiling sequential keras model')\n",
    "# Compile Keras model\n",
    "model.compile(\n",
    "  # cannot use Adagrad with mirroredstartegy https://github.com/tensorflow/tensorflow/issues/19551\n",
    "  #optimizer=tf.optimizers.Adagrad(learning_rate=0.05),\n",
    "  #optimizer=tf.optimizers.SGD(learning_rate=0.05),\n",
    "  #optimizer=tf.optimizers.Adam(learning_rate=0.0005),\n",
    "  #optimizer=tf.optimizers.Adam(),\n",
    "  optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.1),\n",
    "  #optimizer=tfa.optimizers.SGDW(learning_rate=0.01, weight_decay=0.001),\n",
    "  #optimizer=tf.optimizers.Adagrad(),\n",
    "  #optimizer=tfa.optimizers.LazyAdam(learning_rate=0.0001),\n",
    "\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "#log_dir= os.path.join(model_dir, \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "log_dir= os.path.join(model_dir, \"logs\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "log_dir=log_dir,\n",
    "histogram_freq=1,\n",
    "embeddings_freq=1)\n",
    "\n",
    "checkpoints_dir= os.path.join(model_dir, \"checkpoints\")\n",
    "# crashing https://github.com/tensorflow/tensorflow/issues/27688\n",
    "if not os.path.exists(checkpoints_dir):\n",
    "  os.makedirs(checkpoints_dir)\n",
    "\n",
    "callbacks=[]\n",
    "train_time_callback = TrainTimeCallback()\n",
    "batch_summary_callback = BatchAccuracyAndLossSummaryCallback(log_dir, DATASET_SIZE)\n",
    "\n",
    "checkpoints_file_path = checkpoints_dir + \"/epochs:{epoch:03d}-accuracy:{accuracy:.3f}.hdf5\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoints_file_path, verbose=1, mode='max')\n",
    "#callbacks=[tensorboard_callback, checkpoint_callback, batch_summary_callback, train_time_callback]\n",
    "#callbacks=[tensorboard_callback, checkpoint_callback, train_time_callback]\n",
    "callbacks=[PlotLossesCallback(), tensorboard_callback, checkpoint_callback, train_time_callback]\n",
    "\n",
    "verbosity = 2\n",
    "logging.info('training keras model')\n",
    "training_ds = read_raw_kaggle_gcs(True)\n",
    "validation_ds = read_raw_kaggle_gcs(False)\n",
    "model.fit(\n",
    "    training_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=verbosity,\n",
    "    validation_data=validation_ds,\n",
    "    callbacks=callbacks)\n",
    "#model.fit(training_ds, epochs=EPOCHS, verbose=verbosity, callbacks=callbacks)\n",
    "logging.info(\"done training keras model, evaluating model\")\n",
    "loss, accuracy = model.evaluate(validation_ds, verbose=verbosity, steps=get_validation_steps_per_epoch(), callbacks=[])\n",
    "logging.info(\"Eval - Loss: {}, Accuracy: {}\".format(loss, accuracy))\n",
    "logging.info(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
